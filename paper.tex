\documentclass[twoside]{article}

\usepackage{aistats2020}
% If your paper is accepted, change the options for the package
% aistats2020 as follows:
%
%\usepackage[accepted]{aistats2020}
%
% This option will print headings for the title of your paper and
% headings for the authors names, plus a copyright note at the end of
% the first column of the first page.

% If you set papersize explicitly, activate the following three lines:
%\special{papersize = 8.5in, 11in}
%\setlength{\pdfpageheight}{11in}
%\setlength{\pdfpagewidth}{8.5in}

% If you use natbib package, activate the following three lines:
\usepackage[round]{natbib}
\renewcommand{\bibname}{References}
\renewcommand{\bibsection}{\subsubsection*{\bibname}}

% If you use BibTeX in apalike style, activate the following line:
\bibliographystyle{apalike}

% graphics
\usepackage{hyperref}
\usepackage{float}
\usepackage{graphicx}
\usepackage[usenames,dvipsnames,svgnames]{xcolor}

% math and stuff
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{bm}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}

% use straight double quotes in math mode
\DeclareMathSymbol{\mathdblquotechar}{\mathalpha}{letters}{`"}
\newcommand{\mathdblquote}{\mathtt{\mathdblquotechar}}
\begingroup\lccode`~=`"\lowercase{\endgroup
  \let~\mathdblquote
}
\AtBeginDocument{\mathcode`"="8000 }

% algorithmic
\algrenewcomment[1]{\(\triangleright\) #1}
\algnewcommand{\LineComment}[1]{\State \(\triangleright\) #1}
%\algblock[Foo]{execute}{end}

\algblockx[exec]{execute}{END}%
    [1][Unknown]{Execute #1}%
    [1][Unknown]{\vspace{-4mm}}

% code listings
\usepackage{listings}
\lstset{
    literate={~} {$\color{black} \bm{\sim}$}{1}
}
\usepackage[framemethod=tikz]{mdframed}
\input{genlisting}
%\definecolor{codegray}{gray}{0.96}Z
\definecolor{addresscolor}{RGB}{22, 88, 12}
\definecolor{distcolor}{RGB}{40, 12, 88}
\definecolor{gencode}{RGB}{255,235,150}
%^\definecolor{jlcode}{RGB}{255, 247, 247}
\definecolor{jlcode}{RGB}{255,210,210}
%\definecolor{dslcode}{RGB}{247, 255, 230}
\definecolor{dslcode}{RGB}{220,242,255}
\usepackage{colortbl}


%\newcommand{\disc}{\mathrm{disc}}
%\newcommand{\cont}{\mathrm{cont}}
%\newcommand{\tr}{\mathtt{tr}}
%\newcommand{\model}{\mathcal{P}}
%\newcommand{\proposal}{\mathcal{Q}}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newcommand{\true}{{\mathtt{T}}}
\newcommand{\false}{{\mathtt{F}}}
\newcommand{\reals}{\mathbb{R}}
\newcommand{\naturals}{\mathbb{N}}
\newcommand{\integers}{\mathbb{Z}}
\newcommand{\normal}{\mathcal{N}}
\newcommand{\unif}{\mathcal{U}}

\begin{document}

% If your paper is accepted and the title of your paper is very long,
% the style will print as headings an error message. Use the following
% command to supply a shorter title of your paper so that it can be
% used as headings.
%
%\runningtitle{I use this title instead because the last one was very long}

% If your paper is accepted and the number of authors is large, the
% style will print as headings an error message. Use the following
% command to supply a shorter version of the authors names so that
% they can be used as headings (for example, use only the surnames)
%
%\runningauthor{Surname 1, Surname 2, Surname 3, ...., Surname n}

\twocolumn[

\aistatstitle{Automating Involutive MCMC using Probabilistic and Differentiable Programming}

\aistatsauthor{ Marco Cusumano-Towner \And Alexander K. Lew \And Vikash K. Mansinghka }

\aistatsaddress{ Massachusetts Institute of Technology } ]

\begin{abstract}
Involutive MCMC is a unifying mathematical construction for MCMC kernels that generalizes many classic and state-of-the-art MCMC algorithms, from reversible jump MCMC to kernels based on deep neural networks.
But like MCMC samplers more generally, implementing involutive MCMC kernels is often tedious and error-prone, especially when sampling on complex state spaces.
This paper describes a technique for automating the implementation of involutive MCMC kernels given (i) a pair of probabilistic programs defining the target distribution and an auxiliary distribution respectively and (ii) a differentiable program that transforms the execution traces of these probabilistic programs.
The technique, which is implemented as part of the Gen probabilistic programming system, also automatically detects user errors in the specification of involutive MCMC kernels and exploits sparsity in the kernels for improved efficiency.
The paper shows example Gen code for a split-merge reversible jump move in an infinite Gaussian mixture model and a state-dependent mixture of proposals on a combinatorial space of covariance functions for a Gaussian process.
\end{abstract}

\section{INTRODUCTION}
Markov chain Monte Carlo (MCMC) algorithms are powerful tools for approximate sampling from probability distributions and are central to modern Bayesian statistics, probabilistic machine learning, statistical physics, and numerous applications of probabilistic inference.
But designing and deriving efficient MCMC algorithms is mathematically involved, and implementing MCMC kernels is tedious and notoriously error-prone.
These challenges are especially pertinent when sampling from probability distributions on complex state spaces that combine symbolic, numeric, and structural uncertainty, such as those arising in computational biology~\citep{huelsenbeck2004bayesian}, robotics and scene understanding~\citep{geiger2011generative}, and models of human cognition~\citep{tenenbaum2011grow}.

Involutive MCMC is a mathematical construction for MCMC kernels that gives a simplifying and unifying perspective on a number of previously disparate classes of kernels,
including reversible jump MCMC~\citep{green1995reversible}, which is the dominant mathematical framework for MCMC on complex state spaces.
Involutive MCMC constructs an MCMC kernel from three components: (i) the unnormalized target density, (ii) a sampler and density for an auxiliary probability distribution (iii) an involution\footnote{a bijection that is its own inverse ($f$ where $f(f(z)) = z$)} on an extended state space.
While this construction is mathematically clarifying, correctly implementing involutive MCMC kernels on complex state spaces remains challenging due to tedious density and Jacobian computations and the need for careful reasoning about the state space.

This paper formulates involutive MCMC on general state spaces and shows how to automate the implementation of an involutive MCMC kernel from three declarative programs that define the target probability distribution, auxiliary probability distribution, and the involution, respectively.
The probability distributions are defined as probabilistic programs, and the involution is defined as a differentiable program that transforms the execution traces of the probabilistic programs.
We use probabilistic programming techniques and automatic differentiation to automatically compute the acceptance probability.
We also show how to automatically detect mathematical errors in the specification of an involutive MCMC kernel, and how to improve the efficiency by automatically exploiting the sparsity structure in the involution.
We implemented the approach within the Gen probabilistic programming system\footnote{\url{https://www.gen.dev}}~\citep{cusumano2019gen}.
The paper shows examples of involutive MCMC kernels implemented in Gen for (i) a split-merge reversible jump move in an infinite mixture model, and a (ii) state-dependent mixture of Metropolis-Hastings proposals on an infinite combinatorial space of covariance functions for a Gaussian process.
We also provide a lightweight PyTorch implementation of the basic approach at
{\small\url{https://github.com/probcomp/autoimcmc}}.

The contributions of this paper include:
\begin{enumerate}
\item A measure-theoretic formulation of involutive MCMC on general state spaces.
\item A mathematical formulation of state spaces consisting of arbitrary key-value stores (i.e. dictionaries) that formalizes the space of execution traces of Gen probabilistic programs, and a formulation of involutive MCMC on these spaces.
\item A differentiable programming language for defining bijections between spaces of traces of probabilistic programs.
\item An algorithm that automates the implementation of an involutive MCMC kernel given two probabilistic programs and a differentiable program encoding the involution, using automatic differentiation and tracing of probabilistic programs.
\item An extension to the algorithm that exploits sparsity in the involution to reduce the computational complexity of an involutive MCMC kernel from $O(N^2)$ to $O(1)$ in common cases where $N$ is the dimensionality of the latent space.
\item An algorithm that dynamically detects errors in the specification of an involutive MCMC kernel.
\end{enumerate}

\section{RELATED WORK}

The involutive MCMC construction was previously implemented~\citep{gen-inv-mcmc} by the authors as part of the inference library of the Gen probabilistic programming system~\citep{cusumano2019gen}.
The construction was motivated in part by a desire for a simple interface that automated the implementation of reversible jump MCMC samplers~\citep{green1995reversible}, state-dependent mixtures of proposals on complex state spaces, and data-driven neural proposals.
Gen's involutive MCMC construction has since been used by a number of researchers to design and implement MCMC algorithms in diverse domains including computational biology~\citep{merrell2020inferring} and artificial intelligence~\citep{zhi2020online}.

\citet{imcmc} independently identified the involutive MCMC construction as a unifying framework for MCMC algorithms, and showed how a number of classic and recent MCMC algorithms can be cast within this framework.
\citet{imcmc} also identified design principles for developing new MCMC algorithms using the involutive MCMC construction, and showed that the framework aids in the derivation of novel efficient MCMC algorithms.

The involutive MCMC construction encompasses many existing classes of MCMC kernels, some of which explicitly make use of bijective or involutive deterministic maps.
In particular, the reversible jump framework~\citep{green1995reversible,hastie2012model} employs a family of continuously differentiable bijections between the Euclidean parameter spaces of different models.
\citet{tierney1998note} described a family of deterministic proposals based on a deterministic involution that is equivalent to involutive MCMC but without the auxiliary proposal distribution.
More recently,~\citet{spanbauer2020deep} defined a class of deep generative model based on differentiable involutions and trained these models to serve as efficient proposal distributions on continuous state spaces; the resulting algorithm is an instance of the construction presented in this paper.
%Gen~\citet{cusumano2019gen}
%Gen's involution MCMC construct~\citet{gen-inv-mcmc}
%Reversible jump MCMC~\citet{green1995reversible}
%^Using probabilistic programs as proposals~\citet{cusumano2018using}
%Reversible jump probabilistic programming~\citet{roberts2019reversible}




\section{INVOLUTIVE MCMC ON GENERAL STATE SPACES} % on traces ??

Involutive MCMC is a general framework for constructing MCMC kernels that are stationary
for a target probability distribution $p$. Informally, the algorithm works as follows: starting at some state $x$, we first sample
an auxiliary variable $y \sim q_x$ from a state-dependent auxiliary distribution. We then apply an \textit{involution} $f$ to the pair $(x, y)$ to obtain $(x', y')$. 
Finally, we computes an acceptance probability $\alpha$ and either accept $x'$ as the new state, or reject it and repeat the previous state $x$.
Different choices of $q$ and $f$ recover many algorithms from the literature~\citep{imcmc}.

In this section, we present involutive MCMC for models $p$ and auxiliary kernels
$q$ defined over general state spaces.
By emphasizing general state spaces, we intend to clarify
a potential point of confusion regarding the involutive MCMC algorithm: as presented by
\citet{imcmc},
the acceptance probability $\alpha$ depends on the Jacobian of the involution $f$, but
it is not immediately clear how to define this Jacobian when $f$ may operate on samples
from arbitrary measurable spaces, rather than on vectors in $\mathbb{R}^n$. Our 
reformulation of the algorithm below is general enough to handle arbitrary model and auxiliary
distributions, and precise enough to enable automation via probabilistic and differentiable
programming: the rest of this paper uses it to develop a technique for deriving efficient implementations
of involutive MCMC algorithms automatically, 
given only declarative specifications of $p$, $q$, and $f$.

\subsection{General Involutive MCMC}

Let $(X, \Sigma_P, \mu_P)$ and $(Y, \Sigma_Q, \mu_Q)$ denote two general measure spaces with $\sigma$-finite $\mu_P$ and $\mu_Q$. 
Involutive MCMC (Algorithm~\ref{alg:involutive-mcmc}) implements a transition kernel that is invariant for a \textit{model distribution} given by $p : X \to [0, \infty)$, a probability density over $X$ with respect to $\mu_P$. Each iteration, the algorithm first samples auxiliary variables $y \in Y$ from an \emph{auxiliary distribution} $q_x$ based on the model's current state $x$: for each $x \in X$ such that $p(x) > 0$, $q_x : Y \to [0, \infty)$ is a probability density with respect to $\mu_Q$.

The resulting pair $(x, y)$ of the current model state and the newly sampled auxiliary state will be an element of the joint space $Z := \{(x, y) \in X \times Y \mid p(x) q_x(y) > 0 \}$. We can equip $Z$ with the $\sigma$-algebra 
$\Sigma := \{A \cap Z \mid A \in \Sigma_P \otimes \Sigma_Q\}$ (assuming $Z$ is a $\mu_P \times \mu_Q$-measurable set), and a reference measure $\mu(A) := (\mu_P \times \mu_Q)(A)$. 

Let $f : Z \to Z$ denote an involution ($f^{-1} = f$) such that the pushforward of $\mu$ under $f$, denoted $\mu \circ f^{-1}$, is absolutely continuous with respect to $\mu$, with Radon-Nikodym derivative $d (\mu \circ f^{-1}) / d\mu : Z \to [0, \infty)$. Involutive MCMC runs $f$ on $(x, y)$ to obtain $(x', y')$, then computes an acceptance probability $\alpha$.
With probability $\alpha$, the new state $x'$ is returned; otherwise, the previous state $x$ is repeated.

\begin{algorithm}[h]
\begin{algorithmic}
\Procedure{involutive-mcmc}{$p$, $q$, $f$, $x$}
    \State $y \sim q_x(\cdot)$ \Comment{Sample auxiliary state}
    \State $(x', y') \gets f(x, y)$ \Comment{Apply involution}
    \State $\alpha \gets
        \displaystyle \frac{p(x') q_{x'}(y')}{p(x) q_{x}(y)} \cdot \left( \frac{d (\mu \circ f^{-1})}{d \mu} (x, y)\right)$
    \State $r \sim \mathrm{Uniform}(0, 1)$
    \State \algorithmicif \, $r \le \alpha$ \algorithmicthen \, \Return $x'$ \algorithmicelse \, \Return $x$ 
\EndProcedure
\end{algorithmic}
\caption{Involutive MCMC}
\label{alg:involutive-mcmc}
\end{algorithm}

\begin{theorem}[Involutive MCMC is stationary]
Involutive MCMC defines a probability kernel $k$ on $X$ that is stationary with respect to the model probability distribution.
That is, $\int_X k_x(B) p(x) d\mu_X(dx) = \int_B p(x) d\mu_X(dx)$ for all $B \in \Sigma_X$.
\end{theorem}
\begin{proof}
The proof is presented in stages in the appendix (see Section~\ref{sec:involution-detailed-balance}, Section~\ref{sec:involution-is-stationary}, and Section~\ref{sec:involutive-mcmc-is-stationary}).
\end{proof}

\subsection{Probability Distributions on Dictionaries}
\label{sec:dists-on-dicts}
While maximally general, the measure-theoretic formulation of involutive MCMC in Algorithm~\ref{alg:involutive-mcmc} is not amenable to an automated implementation, because it does not indicate how to compute the Radon-Nikodym derivative that is required for the acceptance probability, and it is unclear how to specify the probability measures involved.
%When the algorithm is specialized for state spaces consisting of dictionaries, the acceptance probability simplifies and can be computed from standard Jacobian and probability density computations.
%Because dictionaries are flexible objects, the algorithm remains quite general.

While restricting the state space to vectors of real numbers would address these issues, we seek a 
representation that remains flexible enough to represent complex hybrid state spaces with numeric, symbolic, and structure uncertainty.
Therefore, we use state spaces consisting of 
\textit{finite dictionaries} that map (possibly random) keys to (possibly random) values. 
Dictionaries include vectors as a special case (a vector $\mathbf{x} \in \mathbb{R}^n$ can
be represented as a dictionary mapping the keys $1, \dots, n$ to the values $x_1, \dots, x_n$),
but are more flexible: different keys can hold values of different types (e.g. integers, strings), and we
can also consider distributions in which the set of keys is itself random, which is useful for model
selection problems and structure uncertainty more generally.

This section describes probability distributions on dictionaries, and gives a constructive definition of the involutive MCMC acceptance probability in this setting in terms of a Jacobian.
Section~\ref{sec:automating} will then show how probability distributions on dictionaries can be specified with probabilistic programs, and how probabilistic programming techniques can automatically compute probability densities spaces of dictionaries.

\textbf{The space of finite dictionaries.}
We fix a countably infinite set $\mathcal{K}$ of possible keys, such that each key $k$ is either called \emph{discrete} ($k \in \mathcal{I}$) or \emph{continuous} ($k \in \mathcal{J}$), where $\mathcal{K} = \mathcal{I} \cup \mathcal{J}$.\footnote{
It is possible to assign a general measure space to each key, but this is not necessary for our purposes.}
Let $V_k$ denote the set of possible values for key $k$, where $V_k$ is a countable set for each discrete key, and where $V_k = \mathbb{R}^{d_k}$ for each continuous key for some $d_k$.
Given a set of keys $K$, let $V_K = \times_{k \in A} V_k$ denote the set of \textit{assignments} of values to each key.
Then the set of all finite dictionaries is $\mathcal{D} := \bigcup_{K \subset \mathcal{K}, |K| < \infty} \{(K, \mathbf{x}) \mid \mathbf{x} \in V_K\}$. That is, a dictionary specifies 
a finite set of keys $K \subset \mathcal{K}$ at which it has values, and an assignment $\mathbf{x}$ of values $x_k$ for each.

\textbf{Relationship to representation of~\citet{green1995reversible}.}
\citet{green1995reversible} uses a state space that is the countable union of `models', where for each model there is a vector of real-valued parameters.
Dictionaries possesses substantially more structure:
Instead of monolithic `models', dictionaries use a more elaborate discrete state that includes the set of keys and the assignment to the discrete keys.
Also, continuous keys play the role of real-valued parameters, so it is possible to express that a given real-valued parameter is shared between models.
The additional structure of dictionaries enables the automation techniques in Section~\ref{sec:automating}.

\textbf{A measure space of finite dictionaries.}
We associate a measure $\mu_k$ on $V_k$ for each key---the counting measure for each discrete key and the Lebesgue-measure on $\mathbb{R}^{d_k}$ for each continuous key.
For each finite set of keys $K$, we make $V_K$ a measure space using the standard product $\sigma$-algebra $\Sigma_K = \otimes_{k \in A} \Sigma_k$ and the product measure $\mu_K = \times_{k \in A} \mu_k$.
We equip $\mathcal{D}$ with the $\sigma$-algebra $\Sigma_{\mathcal{D}} := \{\bigcup_{K \subset \mathcal{K}, |K| < \infty} \{(K, \mathbf{x}) \mid \mathbf{x} \in B_K\} \mid B_K \in \Sigma_K \, \text{for each finite } K \subset \mathcal{K}\}$ to obtain a measurable space
of dictionaries.
A reference measure $\mu_\mathcal{D}$ on this space can be constructed using the product measures $\mu_K$: we set $\mu(B) := \sum_{A \in \mathcal{K}, |K| < \infty} \mu_K(\{\mathbf{x} \mid (K, \mathbf{x}) \in B\})$.

\textbf{Notation for dictionaries.} Given a dictionary $d = (K, \mathbf{x})$, we write $K_d$ for $K$ and $d[k]$ for the value $x_k$ associated with a key $k \in K$.
We also denote specific dictionaries using notation $\{k_1 \mapsto v_1, k_2 \mapsto v_2, \ldots\}$.
For example, the dictionary $(K, \mathbf{x})$ with $K = \{1, \mathtt{"foo"}\}$ and $x_1 = 0.123$ and $x_{\mathtt{"foo"}} = 5$ is denoted 
$\{1 \mapsto 0.123, \mathtt{"foo"} \mapsto 5\}$.

\textbf{Probability distributions on finite dictionaries.} 
When all keys are discrete, a probability distribution on dictionaries is defined by a $p$ is a probability mass function $p : \mathcal{D} \to [0, 1]$ that assigns a probability $p(m)$ to each dictionary $m \in \mathcal{P}$ such that $\sum_{x \in \mathcal{D}} p(m) = 1$.
More generally a probability distribution on dictionaries is defined by a probability density $p : \mathcal{D} \rightarrow [0, \infty)$ such that $\int p(m) \mu_\mathcal{D}(\text{d}m) = 1$. 
The probability is distributed the finite sets of keys $K \subseteq \mathcal{K}$ where $|K| < \infty$:
\begin{equation}
1 = \int p(m) \mu_\mathcal{D}(\text{d}m) = \sum_{\substack{K \subseteq \mathcal{K}\\|K| < \infty}} \int p(m) \mu_{K}(dm)
\end{equation}
where the probability for each key set $K$ is:
\begin{equation}\label{eq:integral}
\int p(m) \mu_{K}(dm) = \sum_{\mathbf{x}_1} \int_{\mathbb{R}^{d}} p((K, (\mathbf{x}_1, \mathbf{x}_2))) d\mathbf{x}_2
\end{equation}
where $d: = \sum_{k \in A \cap \mathcal{J}} d_{k}$ and where $\mathbf{x}_1$ is an assignment to the discrete choices in $K$ and $\mathbf{x}_2$ is an assignment to the continuous choices.

We now give an example to build intuition.
Consider a generative model of univariate data points $y_1, \dots, y_n$ from a Gaussian mixture with an unknown number of components $k$, each with unknown mean $m_i$ and variance $s_i$. If we place a Gaussian prior on $m_i$, an inverse Gamma prior on $s_i$, and a Poisson prior on $k$, the resulting density on dictionaries $d$ is:
%
\begin{align*}
p(d) =
\begin{array}{l}
p_{\mathrm{poisson}(3)}(d[\mathtt{k}]) \cdot\\
\prod_{i=1}^{d[\mathtt{k}]} p_{\mathrm{normal}(0, 1)}(d[\mathtt{m}_i]) \cdot\\
\prod_{i=1}^{d[\mathtt{k}]} p_{\mathrm{inversegamma}(1, 10)}(d[\mathtt{s}_i]) \cdot\\
\prod_{i=1}^n  \frac{1}{d[\mathtt{k}]} \sum_{j=1}^{d[\mathtt{k}]} \cdot p_{\mathrm{normal}(d[\mathtt{m}_j], d[\mathtt{s}_i])}(d[\mathtt{y}_i])
\end{array}
\end{align*}
%
when $K_d = \{\texttt{k}, \texttt{y}_\texttt{1}, \dots, \texttt{y}_\texttt{n}\} \cup \{\texttt{m}_i \mid 1 \leq i \leq d[\texttt{k}]\} \cup \{\texttt{s}_i \mid 1 \leq i \leq d[\texttt{k}]\}$, and 0 otherwise. In this case, we have $V_\texttt{k} = \mathbb{N}$ with the counting measure for $\mu_\texttt{k}$, and for all other keys $k \in \mathcal{K}$, $V_k = \mathbb{R}$ with the Lebesgue measure for $\mu_k$.
For each $k \in \{0, 1, \ldots\}$, the probability for key set
$\{\texttt{k}, \texttt{y}_\texttt{1}, \dots, \texttt{y}_\texttt{n}\} \cup \{\texttt{m}_i \mid 1 \leq i \leq k\} \cup \{\texttt{s}_i \mid 1 \leq i \leq k\}$
is $p_{\mathrm{poisson}(s)}(k)$ (via Equation~(\ref{eq:integral})).

\textbf{Conditional distributions via disintegration.} Consider a probability density $p$ on the space $\mathcal{D}$ of dictionaries. 
%For a set of keys $K \subset \mathcal{K}$, let $p(A) := \int 1[K_m = A] p(m) \mu_\mathcal{D}(\text{d}m)$, the probability under $p$ of a dictionary with exactly the key set $K$. 
We say a key $k \in \mathcal{K}$ \textit{almost always appears} if $\int \mathbf{1}[k \in K_m] p(m) \mu_\mathcal{D}(\text{d}m) = 1$. Suppose $B$ is a set of keys that almost always appear for $p$, and that $b = (B, \mathbf{b})$ is a dictionary with keys $B$. Furthermore, let $(K_m, \mathbf{m}) \oplus (K_n, \mathbf{n}) := (K_m \cup K_n, \mathbf{m} \times \mathbf{n})$ be the \textit{merge} of two dictionaries $m$ and $n$ defined on disjoint key sets $K_m$ and $K_n$. Then we can define the conditional density $p(d \mid b) := \mathbf{1}[K_d \cap B = \emptyset] \frac{p(d \oplus b)}{\int_{\{m \mid K_m \cap B = \emptyset\}} p(m \oplus b) \mu_\mathcal{D}(\text{d}m)}$ when the denominator is finite. If the reference measure $\mu_k$ associated with each key $k \in B$ is discrete (e.g., the counting measure), then this definition corresponds to the ordinary notion of conditioning on an event (namely, the event that a sample from $p$ agrees with the dictionary $b$ on all keys in $B$). When this is not the case, it corresponds to a more general measure-theoretic notion called disintegration~\citep{chang1997conditioning}. 

Consider the infinite univariate mixture model, and the conditional density given observed data $(B, \mathbf{b}) := \{\mathtt{y}_1 \mapsto y_1, \ldots, \mathtt{y}_{\mathtt{n}} \mapsto y_{\mathtt{n}}\}$.
The conditional density $p(d | b)$ is nonzero only if $K_d = \{\texttt{k}\} \cup \{\texttt{m}_i \mid 1 \leq i \leq k\} \cup \{\texttt{s}_i \mid 1 \leq i \leq k\}$ for some $k$ ($d$ does not contain y-values), and the denominator in the definition of $p(d | b)$ simplifies to the familiar sum of marginal likelihoods over all $k$, where each marginal likelihood is a Riemann integral over $\mathbb{R}^{2k}$.

\begin{figure*}[h!]
    \centering
    \includegraphics[width=0.93\textwidth]{figures/mixture.pdf}
    \caption{
Example of reversible jump MCMC~\citep{green1995reversible} implemented using involutive MCMC in Gen.
The example implements a `split-merge move' in a infinite Gaussian mixture model~\citep{richardson1997bayesian} using three Gen programs:
(1) a probabilistic program $\mathtt{p}$ encoding the generative model (shown in b),
(2) a probabilistic program $\mathtt{q}$ encoding an auxiliary probability distribution (shown in c),
and (3) a differentiable program $\mathtt{h}$ that encodes an involution on the space of pairs of traces of $\mathtt{p}$ and $\mathtt{q}$ (shown in d).
Gen's involutive MCMC operator (shown in e) automatically computes the acceptance probability.
}
    \label{fig:mixture}
\end{figure*}

\subsection{Involutive MCMC with Dictionaries}

% TODO consider adding this back, to explain to reader why they are reading this:
%The general measure-theoretic formulation of involutive MCMC in Algorithm~\ref{alg:involutive-mcmc} does not specify how to compute the Radon-Nikodym derivative that is required for the acceptance probability.
%When the algorithm is specialized for state spaces consisting of dictionaries, the acceptance probability simplifies and can be computed from standard Jacobian and probability density computations.
%Because dictionaries are flexible objects, the algorithm remains quite general.

Suppose that the model distribution and auxiliary distributions are probability distributions on dictionaries, with densities $p$ and $q_x$.
Then, $X$ and $Y$ are both sets of dictionaries, and the joint space $Z$ is a set of pairs $(x, y)$ of dictionaries with keys $\mathcal{K}_P$ and $\mathcal{K}_Q$ respectively, so that $Z = X \times Y \subseteq \mathcal{D}_P \times \mathcal{D}_Q$ where $\mathcal{D}_P$ is the set of dictionaries on keys taken from $\mathcal{K}_P$ and similarly for $\mathcal{D}_Q$.
% TODO: this is only needed for Algorithm 2, and it is relevant for the 
To simplify the notation, and without loss of generality, we will assume that $\mathcal{K}_P$ and $\mathcal{K}_Q$ are disjoint\footnote{If $\mathcal{K}_P$ and $\mathcal{K}_Q$ are not disjoint then, they can be made so by adding a different prefix to the keys of each set.}, and we define $Z := \{ x \oplus y : p(x)q_x(y) > 0\} \subseteq \mathcal{D}$.
where $\mathcal{D}$ is the set of dictionaries on keys from $\mathcal{K}_P \cup \mathcal{K}_Q$
(recall $x \oplus y$ denotes the dictionary resulting from merging dictionaries $x$ and $y$ with disjoint keys).

Suppose there is a countable partition of $Z$ into $\{Z_e : e \in E\}$ such that across each $Z_e$ the sets of keys $K_x$ and $K_y$ and the values $x_k$ and $y_k$ for all discrete keys $k$ are both constant.
Then each set $Z_e$ is isomorphic to a Euclidean space of assignments to the continuous keys in the two dictionaries.
Suppose there is an involution $g : E \to E$ between elements of the partition (a function with $g = g^{-1}$), and a family of continuously differentiable bijections $h_{e} : Z_e \to Z_{g(e)}$ for each $e$ with $h_{e} = h_{g(e)}^{-1}$.
Let $e(z) \in E$ denote the element of the partition for an alement $z \in Z$.
Then, $f : Z \to Z$ given by $f(z) := h_{e(z)}(z)$ is an involution:
\begin{equation*}
f(f(z)) = h_{e(f(z))}(h_{e(z)}(z)) = h_{g(e(z))}(h_{e(z)}(z)) = z
\end{equation*}
Let $|J h_e|(z)$ denote the absolute value of the Jacobian (determinant) of $h_e$, evaluated at $z$.
Then, the acceptance probability in Algorithm~\ref{alg:involutive-mcmc} simplifies to:
\begin{equation} \label{eq:acceptance-ratio-dictionaries}
\frac{p(x') q_{x'}(y')}{p(x) q_{x}(y)} \cdot |J h_e|(z)
\end{equation}
One example of a valid partition of $Z$ is given by equivalence classes of the following equivalence relation:
\[
z_1 \sim z_2 \iff (K_{z_1} = K_{z_2}) \land (z_1[k] = z_2[k] \; \forall k \in K_{z_1} \cap \mathcal{I})
\]
(dictionaries are equivalent if they contain the same keys and they agree on the value of all discrete keys).
Section~\ref{sec:radon-nikodym-special-case} of the appendix for details.


\section{AUTOMATING INVOLUTIVE MCMC WITH TRACES} \label{sec:automating}

\begin{algorithm*}[h]
\begin{algorithmic}
\Require probabilistic programs $\mathcal{P}$ and $\mathcal{Q}$; differentiable program $\mathcal{F}$; initial state $x$
\vspace{1mm}
\Procedure{auto-involutive-mcmc}{$\mathcal{P}$, $\mathcal{Q}$, $\mathcal{F}$, $x$}
    \State $(y, \log q_x(y)) \gets \textproc{trace-and-score}(\mathcal{Q}_x)$ \Comment{Sample $y \sim q_x(\cdot)$; compute log-density via probabilistic program}
    \State $(x' \oplus y', \log D) \gets \textproc{run-involution}(\mathcal{F}, x \oplus y)$ \Comment{{\small Compute $(x' \oplus y') = f(x \oplus y)$ and log(Radon-Nikodym derivative)}}
    \State $\log p(x) \gets \textproc{score}(\mathcal{P}, x)$ \Comment{Compute log-density via probabilistic program}
    \State $\log p(x') \gets \textproc{score}(\mathcal{P}, x')$ \Comment{Compute log-density via probabilistic program}
    \State $\log q_{x'}(y') \gets \textproc{score}(\mathcal{Q}_{x'}, y')$ \Comment{Compute log-density via probabilistic program}
    \State $\alpha \gets \min\{1, \exp(\log p(x') - \log p(x) + \log q_{x'}(y') - \log q_x(y) + \log D)\}$ \Comment{Compute acceptance probability}
    \State \textbf{with probability} \,$\alpha$ \,\Return $x'$ \algorithmicelse \, \Return $x$  \algorithmicend
\EndProcedure\\
\vspace{1mm}
\begin{minipage}[t]{0.49\linewidth}
\Procedure{trace-and-score}{$\mathcal{P}$}
   \State $s \gets 0$
   \State $x \gets \{\}$
   \execute[$\mathcal{P}$], but with $\mathtt{"}k \sim \mathrm{distribution}\mathtt{"} \equiv$ (
        \State 1. set $v \sim \mathrm{distribution}$
        \State 2. set $x[k] \gets v$
        \State 3. set $s \gets s + \textproc{logpdf}(\mathrm{distribution}, v)$
        \State 4. evaluate to $v$)
    \END
   \State \Return $(x, s)$
\EndProcedure
\end{minipage}%
\hfill
\begin{minipage}[t]{0.49\linewidth}
\Procedure{score}{$\mathcal{P}$, $x$}
    \State $s \gets 0$
    \State $K \gets\{\}$
    \execute[$\mathcal{P}$], but with $\mathtt{"}k \sim \mathrm{distribution}\mathtt{"} \equiv$ (
        \State 1. set $v \gets x[k]$
        \State 2. set $K \gets K \cup \{k\}$
        \State 3. set $s \gets s + \textproc{logpdf}(\mathrm{distribution}, v)$
        \State 4. evaluate to $v$)
    \END
   \State \algorithmicif\hspace{1mm} $K \ne K_x$ \algorithmicthen\hspace{1mm} $s \gets -\infty$ \algorithmicend
   \State \Return $s$
\EndProcedure
\end{minipage}\\
\vspace{1mm}
\Procedure{run-involution}{$\mathcal{F}$, $z$}
% TODO would be much simpler to describe if we didn't have to separate out x and y..
    \LineComment{Run the involution, and keep track of copied, read, and written continuous keys}
    \State $z' \gets \{\}$ \Comment{Initialize empty output dictionary}
    \execute[$\mathcal{F}$], but with
        \State $\mathtt{"@write}(k, v)\mathtt{"} \equiv$
            (\algorithmicif\hspace{1mm} $k \in \mathcal{I}$
            \algorithmicthen\hspace{1mm} set $z'[k] \gets v$
            \algorithmicelse\hspace{1mm} set $z'[k] \gets v$ and set $W \gets W \cup \{k\})$
        \State $\mathtt{"@read}(k)\mathtt{"} \equiv$
            (\algorithmicif\hspace{1mm} $k \in \mathcal{I}$
            \algorithmicthen\hspace{1mm} evaluate to $z[k]$
            \algorithmicelse\hspace{1mm} set $R \gets R \cup \{k\}$ and evaluate to $z[k]$)
        \State $\mathtt{"copy}(k_1, k_2)\mathtt{"} \equiv$ (set $z'[k_2] \gets z[k_1]$ and set $C \gets C \cup \{k_1\}$)
    \END
    \LineComment{Use automatic differentiation of $\mathcal{F}$ to compute Jacobian, skipping copied addresses}
    \For{$i$ in $1$ to $|W|$}
        \State $k_i \gets W_i$ \Comment{Pick $i$th key in $W$; the order does not matter}
        \State $J[i,:] \gets \nabla_{\mathbf{z}_{R \setminus C}} \left( h_{e(z)}[a_i] \right)$ \Comment{{\small Gradient of $z'[k_i] = h_{e(z)}[k_i]$ w.r.t. non-copied continuous inputs ($z_k$ for $k \in R \setminus C$)}}
    \EndFor
    \State \Return $(z', \log(|\det(J)|))$
\EndProcedure
\end{algorithmic}
\caption{Automated Involutive MCMC}
\label{alg:auto-involutive-mcmc}
\end{algorithm*}

Involutive MCMC is a general framework that can be used to develop diverse MCMC algorithms
for models over arbitrary state spaces. We wish to \textit{automate} the implementation
details for involutive MCMC algorithms, given only a specification of the model $p$, the
auxiliary distribution $q$, and the involution $f$.
To do so, we require a representation for the distributions $p$ and $q$ that is flexible
enough to represent the full variety of models and auxiliary distributions of interest to
practitioners. The representation must support density evaluation and sampling. It is also desirable that the representation be \textit{structured}: the more
information available to us (e.g., about the decomposition of a distribution's state space into 
individual univariate and multivariate random variables, or about conditional independence relationships in a model),
the easier it will be for the implementation to exploit this structure automatically by using
more efficient data structures and low-level manipulations.

\subsection{Trace-Based Probabilistic Programming} \label{sec:probabilistic-programming}

\textit{Probabilistic programs} are flexible and structured representations for  probability distributions. Unlike densities (but like Bayesian networks), probabilistic programs can be efficiently sampled and contain explicitly represented information
about some conditional independence relationships in a model. 
But unlike Bayesian networks, they do not assume a fixed number of random variables, state space dimension, or dependency structure.

At the most basic level, a probabilistic program is a program that makes random choices. 
Any such program induces a probability distribution over its possible \textit{execution traces}, records of each random choice it makes.
If each random choice is associated with a unique \textit{address} from the set of
dictionary keys $\mathcal{K}$, 
then these traces can be viewed as finite dictionaries, mapping the address of each random choice to its value. 
The distribution induced by a probabilistic program over
its execution traces can thus be understood as a measure on the space $(\mathcal{D}, \Sigma_\mathcal{D}, \mu_\mathcal{D})$ introduced in the previous section. Furthermore, densities of trace distributions with respect to $\mu_\mathcal{D}$ are typically easy to compute.

In this section, we introduce a probabilistic programming language from the Gen probabilistic programming system~\citep{cusumano2019gen}, and present a technique for automating the implementation of involutive MCMC algorithms when the model $p$ and auxiliary distribution $q_x$ are both represented as
probabilistic programs in this language.
But the technique is not limited to the Gen system---we also provide the implementation of a minimal probabilistic programming language in PyTorch that supports the automation technique.

\subsubsection{A Probabilistic Programming Language}

Our probabilistic programming language augments the syntax of Julia~\citep{bezanson2017julia}
with a single new construct, the \texttt{\{a\} $\sim$ d} expression, for making a \textit{named} random choice. An execution trace of a Gen probabilistic program can be sampled by running the program according to Julia's usual semantics, and upon encountering an expression of the form \texttt{\{a\} $\sim$ d}, (i) evaluating the \textit{address expression} \texttt{a} to obtain an address $k \in \mathcal{K}$; (ii) evaluating the \textit{distribution expression} $d$ to obtain a distribution $d$ over the measurable space $V_k$; (iii) sampling a value $x_k \sim d$ and adding the mapping $\{k \mapsto x_k\}$ to a dictionary called the program trace; and (iv) returning the sampled value $x_k$ to the program, to continue execution. When execution terminates, the program trace has accumulated a mapping for each random choice encountered during the program's execution.

For example, consider the probabilistic program below, which defines a Gaussian mixture model with an unknown number of components:
\noindent
\begin{center}
\begin{tabular}{c}
{\begin{lstlisting}[basicstyle=\small\ttfamily]
@gen function p(n::Int)
  k ~ poisson_plus_one(1)
  means = [
    ({(:mu, j)} ~ normal(0, 10)) for j in 1:k]
  vars = [
    ({(:var, j)} ~ inv_gamma(1, 10)) for j in 1:k]
  weights ~ dirichlet([2.0 for j in 1:k])
  for i in 1:n
    {(:x, i)} ~ mixture_of_normals(
        weights, means, vars)
  end
end
\end{lstlisting}}
\end{tabular}
\end{center}
The program \texttt{p} accepts as input an integer \texttt{n}, a number of data points. Each $\texttt{n}$ defines
a distinct distribution over dictionaries.
The first line of the program samples a number of mixture components from a Poisson prior using the address \texttt{:k}. (This line could also be written \texttt{k = \{:k\} $\sim$ poisson\_plus\_one(1)}: the \textit{address} is the symbol \texttt{:k}, and the result of the choice is assigned to a Julia variable called \texttt{k}. Because this is a common pattern, Gen provides the syntactic sugar \texttt{x $\sim$ d} as shorthand for \texttt{x = \{:x\} $\sim$ d}.) The program then samples \texttt{k} means and \texttt{k} variances from Gaussian and inverse Gamma priors, respectively. Each of these 2\texttt{k} random choices has its own address, determined by the address expression preceding it. For example, the mean for the fourth mixture component (if \texttt{k} $\geq 4$) has address \texttt{(:mu, 4)}. The mixture weights are then sampled at the address \texttt{:weights} from a Dirichlet distribution, and $\texttt{n}$ data points are sampled at addresses \texttt{(:x, 1)}, \dots, \texttt{(:x, n)}. The random choice at address $\mathtt{:}\mathtt{k}$ is discrete with $V_{\texttt{:k}} = \integers_{\ge 1}$, and the other random choices are continuous. 
Overall, the program defines a distribution over traces with the following density over traces $(K, \mathbf{x})$ with respect to $\mu_\mathcal{D}$:
\begin{align*}
p(n)((K, \mathbf{x})) =
\begin{array}{l}
p_{\mathrm{poisson}(1)}(x_{\mathtt{:}\mathtt{k}}-1) \cdot\\
\prod_{i=1}^{x_{\mathtt{:}\mathtt{k}}} p_{\mathrm{normal}(0, 10)}(x_{(\mathtt{:}\mathtt{mu}, i)}) \cdot\\
\prod_{i=1}^{x_{\mathtt{:}\mathtt{k}}} p_{\mathrm{inversegamma}(1, 10)}(x_{(\mathtt{:}\mathtt{var}, i)}) \cdot\\
p_{\mathrm{dirichlet}(2.0,\dots,2.0)}(x_{\mathtt{:}\mathtt{weights}})\cdot\\
\prod_{i=1}^n \sum_{j=1}^{x_{\mathtt{:}\mathtt{k}}} x_{\mathtt{:}\mathtt{weights}}[j] \cdot\\
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; p_{\mathrm{normal}(x_{\mathtt{(:mu, j)}}, x_{(\mathtt{:}\mathtt{var}, j)})}(x_{(\mathtt{:}\mathtt{x}, i)})
\end{array}
\end{align*}
when $K$ contains exactly the addresses $\mathtt{:}\mathtt{k}, \mathtt{:}\mathtt{weights}, (\mathtt{:}\mathtt{x}, i)$ for $i = 1, \dots, n$, and $(\mathtt{:}\mathtt{mu}, j)$ and $(\mathtt{:}\mathtt{var}, j)$ for $j = 1, \dots, x_{\mathtt{:}\mathtt{k}}$; otherwise, the density is 0.

\paragraph{Automatic Sampling and Density Computation for Probabilistic Programs.}
Sampling traces from, and computing densities of dictionaries under, the distribution on traces
induced by a probabilistic program is straight-forward to do, using a standard technique
in probabilistic programming.

We illustrate this technique in the \textsc{trace-and-score} and \textsc{score} subroutines in Algorithm~\ref{alg:auto-involutive-mcmc}.
The \textsc{trace-and-score} subroutine samples a trace by running a probabilistic program,
but recording the value of every encountered choice into a dictionary, which it returns once execution has terminated. It also returns the log density of the trace, calculated by accumulating densities of the individual choices it encounters. (Note that this procedure is only valid if the program
halts with probability 1. Otherwise, it could loop infinitely, and even if it terminates,
the density will be incorrect.) 

The density of an arbitrary dictionary $(K, \mathbf{x})$ under any probabilistic program's distribution on traces can be computed using \textsc{score}. The idea is to run the probabilistic program, and whenever a random choice \texttt{\{a\} $\sim$ d} is encountered, to look up the value $x_k$ in the dictionary, compute its density under the primitive distribution $d$, multiply this density into a running total, and return control to the probabilistic program as if the sampling instruction had executed and returned $x_k$. At the end, the running total can be returned as the trace's density. If at any point an address $k \not\in K$ is encountered, or if not all addresses in $K$ have been visited at the end of execution, the algorithm returns $0$ as the density.

\subsubsection{Automatically Computing Density Ratios in Involutive MCMC}

If the two probabilistic programs $\mathcal{P}$ and $\mathcal{Q}$ satisfy a simple technical requirement (described in Section~\ref{sec:technical-requirement}), we can interpret them as specifying the model density $p$ and auxiliary densities $q_x$ for use with involutive MCMC on dictionaries (Algorithm~\ref{alg:involutive-mcmc}). (In this case, the program $\mathcal{Q}$ 
accepts a trace $x$ of $\mathcal{P}$ as input, and the distribution for $q_x$ is given by $\mathcal{Q}_x$.)

However, typically, we cannot use a probabilistic program $\mathcal{P}$ to represent the target distribution directly: probabilistic programs implement simulators for a distribution, but target densities are typically not tractable to simulate (hence the need for MCMC). Instead, we may wish to sample from a target $p$ that arises from conditioning a probabilistic program $\mathcal{P}$'s distribution over traces on observations of the values at some addresses. Let $\tilde{p}$ denote $\mathcal{P}$'s distribution over traces, and let $b = (B, \textbf{b})$ be a dictionary of observations, as described in Section~\ref{sec:dists-on-dicts}. Then, as shown in that section, the target distribution $p(x) = \tilde{p}(x \mid b) = \frac{\tilde{p}(x \oplus b)}{\mathcal{L}(b)}$, where $\mathcal{L}(b) = \int_{\{m \mid m \cap B = \emptyset\}} p(m \oplus b) \mu_\mathcal{D}(\text{d}m)$ is the marginal likelihood of $b$, and does not depend on $x$. Then $\tilde{p}(x \oplus b) = \mathcal{L}(b)p(x)$. If we use $\tilde{p}(x \oplus b)$ in place of $p(x)$ to compute the ratio of densities in Algorithm~\ref{alg:involutive-mcmc}, we will wind up with the same output, because $\mathcal{L}(b)$ will cancel in the numerator and denominator:
\begin{equation}
\frac{p(x') q_{x'}(y')}{p(x) q_{x}(y)}
= \frac{\tilde{p}(x' \oplus b) q_{x'}(y')}{\tilde{p}(x \oplus b) q_x(y)}
= \frac{\tilde{p}(x' | b) q_{x'}(y')}{\tilde{p}(x | b) q_x(y)}
\end{equation}

Thus, this ratio can be computed term-by-term using \textsc{score} on the probabilistic programs $\mathcal{P}$ and $\mathcal{Q}$: (Algorithm~\ref{alg:auto-involutive-mcmc}): to compute $q_x(y')$, we run the algorithm directly on the program $\mathcal{Q}_x$, and to compute $p(x)$ and $p(x')$, we actually merge the dictionary $x$ with the observations $b$ and compute $\mathcal{L}(b)p(x) = \tilde{p}(x \oplus b)$ instead, by running the algorithm on $\mathcal{P}$ with trace $x \oplus b$. The density $q_x(y)$ can be computed while $y$ is being sampled, using \textsc{trace-and-score}.

Section~\ref{sec:sparsity} describes a more efficient approach that exploits sparsity in the involution and resulting cancellation in the ratio for improved efficiency, but requires a more sophisticated probabilistic programming runtime system.

Figure~\ref{fig:mixture}b and Figure~\ref{fig:mixture}c show examples of probabilistic programs $\mathcal{P}$ and $\mathcal{Q}$ respectively, for a split-merge reversible jump move.

\subsection{Differentiable Programming with Traces} \label{sec:differentiable-programming-traces}

Section~\ref{sec:probabilistic-programming} showed that if the densities $p$ and $q$ are specified using probabilistic programs $\mathcal{P}$ and $\mathcal{Q}$, then density ratio in the acceptance probability for involutive MCMC on dictionaries Equation~(\ref{eq:acceptance-ratio-dictionaries}) can be automated using probabilistic programming techniques.
This section shows that if the involution $f$ is specified in using a differentiable program $\mathcal{F}$ that transforms the execution traces of probabilistic programs, then the Jacobian factor in Equation~(\ref{eq:acceptance-ratio-dictionaries}) can be automated using automatic differentiation.
The procedure \textproc{auto-involutive-mcmc} in Algorithm~\ref{alg:auto-involutive-mcmc} combines these two ideas and automates involutive MCMC given the programs $\mathcal{P}$, $\mathcal{Q}$, and $\mathcal{F}$.

%The previous section described how the probability densities ($p$ and $q$) required for involutive MCMC on spaces of dictionaries can be specified and automatically computed using probabilistic programs.
%This section introduces a lightweight differentiable programming language for specifying involutions ($f : Z \to Z$) on dictionaries.
%The interpreter for the language computes the Radon-Nikodym derivative required for the acceptance probability using automatic differentiation.
%The language is implemented as part of the Gen system~\citep{cusumano2019gen}, which is embedded in the Julia language.
%We also provide a simplified PyTorch-based implementation of the language.

\subsubsection{A Differentiable Programming Language for Manipulating Traces}
Recall that for involutive MCMC on a state space of dictionaries, we define $Z := \{x \oplus y : p(x) q_x(y) > 0\} \subseteq \mathcal{D}$, where $x \oplus y$ is the dictionary resulting from merging dictionaries $x$ and $y$ with disjoint keys.
The involution is a function $f : Z \to Z$.
%Intuitively, $z = x \oplus y$ the trace of a composite probabilistic program constructed by running $\mathcal{P}$ first, and then running $\mathcal{Q}$, passing the trace of $\mathcal{P}$ as its input.

We now introduce a simple differentiable programming language for specifying involutions $f$.
The language needs to have syntax for reading the value from an address in $x \oplus y \in Z$ and writing to an address in $x' \oplus y' \in Z$.
To read a value $(x \oplus y)[a]$ at address $a$, we use the \texttt{@read} keyword:
\noindent
\begin{center}
\begin{tabular}{c}
{\begin{lstlisting}[basicstyle=\small\ttfamily]
    value = @read(<address>, <type>)
\end{lstlisting}}
\end{tabular}
\end{center}
The first argument is the address $a$ and the second argument is either $\mathtt{discrete}$ or $\mathtt{continuous}$, and informs the interpreter whether the random choice at that address is drawn from a discrete or continuous distribution (this information will be used to support automatic differentiation).
Recall that $x$ is the trace of the model probabilistic program, and $y$ is the trace of the auxiliary probabilistic program.
Each address $a$ therefore is a pair, where the first element is either $\mathtt{model}$ or $\mathtt{aux}$, and the second element is the address within either $x$ or $y$.
For example, to read the value of a continuous address $\mathtt{:}\mathtt{r}$ from the model trace ($x$):
\noindent
\begin{center}
\begin{tabular}{c}
{\begin{lstlisting}[basicstyle=\small\ttfamily]
    val = @read((model, :r), continuous)
\end{lstlisting}}
\end{tabular}
\end{center}
The syntax for writing to an address in $x' \oplus y' \in Z$ is similar.
For example to write a value $\mathtt{val}$ to $x'[\mathtt{:}\mathtt{r}]$:
\noindent
\begin{center}
\begin{tabular}{c}
{\begin{lstlisting}[basicstyle=\small\ttfamily]
    @write((model, :r), val, continuous)
\end{lstlisting}}
\end{tabular}
\end{center}
Note that the input traces $x, y$ are distinct from the output traces $x', y'$;
input traces can only be read from, and output traces can only be written to.
For example, it is not possible to write an output trace and then read the written value from it later.
Often, we want to simply copy the value from some address in the input traces to some address in the output trace.
While this is possible via a $\mathtt{@read}$ followed by a $\mathtt{@write}$, the language provides a special syntax for copies:
\noindent
\begin{center}
\begin{tabular}{c}
{\begin{lstlisting}[basicstyle=\small\ttfamily]
    @copy(<from-address>, <to-address>)
\end{lstlisting}}
\end{tabular}
\end{center}
Like above, the two addresses here are both pairs of the trace and the address within that trace.
For example, to copy the value from address $\mathtt{:}\mathtt{u}$ in $x$ to address $\mathtt{:}\mathtt{v}$ in $x'$, we use:
\noindent
\begin{center}
\begin{tabular}{c}
{\begin{lstlisting}[basicstyle=\small\ttfamily]
    @copy((model, :u), (model, :v))
\end{lstlisting}}
\end{tabular}
\end{center}
Of course, it is also possible to copy from $x$ to $y'$, from $y$ to $x'$ and from $y$ to $y'$.
As we will see in Section~\ref{sec:sparsity}, it is preferable to copy when possible instead of reading and then writing, as this can improve the efficiency of automatic differentiation.



%We denote a program in the differentiable language by $\mathcal{F}$ and the involution it defines as $f$.
%Like the probabilistic programming language described in the previous section, our differentiable language for involutions on traces is embedded based on Julia.
%The differentiable language has specialized expressions for reading values from addresses in a trace, writing values to the addresses in a trace, and copying values from an address in one trace to an address in another trace.
%The first argument defines what trace we are reading from.
%The second argument is the address in that trace, which may be hierarchical.\footnote{
%Hierarchical addresses of the form $\mathtt{a.b.c}$ are constructed in the language using the syntax \texttt{a=>b=>c}.}
%The third argument is either $\mathtt{:}\mathtt{discrete}$ or $\mathtt{:}\mathtt{continuous}$, and informs the language runtime whether the random choice at that address is drawn from a discrete or continuous distribution (this information will be used to support automatic differentiation).
%Similarly, to write a value to a trace, we use a \texttt{@write} keyword:
%\noindent
%\begin{center}
%\begin{tabular}{c}
%{\begin{lstlisting}[basicstyle=\small\ttfamily]
    %@write(<trace>, <address>, <value>, <type>)
%\end{lstlisting}}
%\end{tabular}
%\end{center}
%The mathematical behavior of the function is defined simply by writing Julia code that implements it.
\paragraph{Constructing an Involution}
The following code reads the values of parameters from the model in polar coordinates and writes out their values in cartesian coordinates:
\noindent
\begin{center}
\begin{tabular}{c}
{\begin{lstlisting}[basicstyle=\small\ttfamily]
r = @read((model, :r), :continuous)
theta = @read((model, :theta), :continuous)
x = r * sin(theta)
y = r * cos(theta)
@write((model, :x), x, :continuous)
@write((model, :y), y, :continuous)
\end{lstlisting}}
\end{tabular}
\end{center}

This code snippet defines a bijection from one coordinate system to another.
However, it does not define an involution, because applying the function the first time produces a trace containing cartesian coordinates, and applying the function a second time to the resulting trace would fail, because the function reads in polar coordinates from its input trace.
How can we make the function an involution?
First, the function will need the ability to go from cartesian coordinates to polar coordinates, so the code for the inverse of the forward transformation must appear in the function somewhere.
Also, to be an involution, the input and output traces must contain some information indicating whether they are using polar or cartesian coordinates, so the involution code knows which of the two transformations to read from, and which addresses to read from and write to.
Below is a minimal example of the involution, that uses a Boolean address polar.
Note that the involution negates the value of this address, to indicate that the coordinate system is switching with each application.
\noindent
\begin{center}
\begin{tabular}{c}
{\begin{lstlisting}[basicstyle=\small\ttfamily]
@tracefn f
   polar = @read((model, :polar), discrete)
   if polar
      r = @read((model, :r), continuous)
      theta = @read((model, :theta), continuous)
      x = r * sin(theta)
      y = r * cos(theta)
      @write((model, :x), x, continuous)
      @write((model, :y), y, continuous)
   else
      x = @read((model, :x), continuous)
      y = @read((model, :y), continuous)
      r = (x^2 + y^2)
      theta = atan(y, x)
      @write((model, :r), r, continuous)
      @write((model, :theta), theta, continuous)
   end
   @write((model, :polar), !polar, discrete)
end
\end{lstlisting}}
\end{tabular}
\end{center}
In order to apply this function in the context of involutive MCMC, we require probabilistic programs $\mathcal{P}$ and $\mathcal{Q}$ that define space of input and output traces for the involution.
The involution only reads and writes to model addresses, so $\mathcal{Q}$ can be an empty program:
\noindent
\begin{center}
\begin{tabular}{c}
{\begin{lstlisting}[basicstyle=\small\ttfamily]
@gen function p()
    polar ~ bernoulli(0.5)
    if polar
        r ~ gamma(1, 1)
        theta ~ uniform(-pi, pi)
    else
        x ~ normal(0, 1)
        y ~ normal(0, 1)
    end
end

@gen function q(x)
end
\end{lstlisting}}
\end{tabular}
\end{center}

\subsubsection{Computing the Jacobian with Automatic Differentiation}

Recall that the involution $f$ must decompose into (i) an involution $g$ on elements $e \in E$ of a partition of the state space, and (ii) a pair of continuous differentiable bijections $h_{e}$ and $h_{g(e)} = h_{e}^{-1}$ between each pair of corresponding elements of the partition.
Each function $h_e$ is a function from the values at continuous addresses in the input trace ($z[a]$ for $a \in A_z \cap \mathcal{J}$) to the values at continuous addresses in the output trace ($z'[a]$ for $a \in A_{z'} \cap \mathcal{J}$).
We compute the Jacobian using automatic differentiation (AD);
different approaches are possible.
The Gen implementation uses forward-mode AD whereas our PyTorch implementation uses reverse-mode AD.
The procedure \textproc{run-involution} in Algorithm~\ref{alg:auto-involutive-mcmc} shows the implementation of the interpreter for the language that uses reverse-mode AD.
The interpreter executes $\mathcal{F}$ using regular Julia or Python semantics, but intercepts calls to \texttt{@write}, \texttt{@read}, and \texttt{@copy} statements, and in addition to performing the desired operation, records the set of continuous addresses that are read, written, and copied.
After $\mathcal{F}$ is finished executing, AD uses the recorded addresses to compute the Jacobian $|J h_e|(z)$; in the case of reverse-mode AD by iterating over output continuous addresses and backpropagating from each one to all of the input continous addresses, computing the Jacobian row-by-row.
Note that the $\mathtt{discrete}$ and $\mathtt{continuous}$ labels are omitted from the syntax in \textproc{run-involution} to simplify notation ($a \in \mathcal{I}$ indicates a discrete choice and otherwise a choice is continuous).

\section{EXPLOITING SPARSITY FOR IMPROVED PERFORMANCE} \label{sec:sparsity}

Suppose $N$ and $N'$ are the total number of random choices in the input traces $x \oplus y$ and output traces $x' \oplus y'$ respectively, and $M$ is the number of continuous random choices (which is the same in the input traces and output traces).
Then, the number of operations requried in Algorithm~\ref{alg:auto-involutive-mcmc} grows as $O(N) + O(M^2)$ (where each call to \textproc{logpdf} and the computation of each entry in the Jacobian both count as one operation).
The linear term represents the complexity of sampling $y'$ and computing the four log-densities used to compute the acceptance probability.
The quadratic term represents the complexity of computing the Jacobian matrix and its determinant.
It is possible to reduce the computational complexity of an automated involutive MCMC kernel by exploiting special structure in the involution $f$, in some cases to $O(1)$.
This section describes how an automated involutive MCMC implementation can reduce the computational complexity of the Jacobian computation and the density ratio computation.
These techniques are used in the Gen implementation of automated involutive MCMC, and one of the techniques is used in our minimal PyTorch implementation.

\subsection{Sparsity-Aware Automatic Jacobian Computation}

The naive implementation of Algorithm~\ref{alg:auto-involutive-mcmc} computes by the Jacobian by first computing the $M$-by-$M$ Jacobian matrix $J h_{e(z)}$ via automatic differentiation, and them computing the absolute value of its determinant.
However, we observe that in many applications of involutive MCMC, the values at continuous choices in the input traces are directly copied into the output traces (either at the same, or different, keys).
These copy operations result in columns in the Jacobian matrix that have a single $1$ entry with remaining entries are $0$.
For example, for the function $(u, v, x, y) \mapsto (u, 2 u - v, y, x) = (u', v', x', y')$, the Jacobian is (with columns corresponding to $u'$, $v'$, $x'$, and $y'$ and rows corresponding to $u$, $v$, $x$, and $y$):
\begin{equation}
\left[
\begin{array}{cccc}
1 & 2 & 0 & 0\\
0 & -1 & 0 & 0\\
0 & 0 & 0 & 1\\
0 & 0 & 1 & 0
\end{array}
\right]
\begin{array}{c}
u\\ v\\ x\\ y
\end{array}
\end{equation}
Using the cofactor expansion of the determinant, we observe that for any (`copy') row or column in an $M$-by-$M$ Jacobian matrix with a single $1$ and all other entries $0$, that absolute value of the determinant is equivalent to that of the $(M-1)$-by-$(M-1)$ sub-matrix with the corresponding row and column omitted (even if that would remove other nonzero entries from the matrix).
By applying this rule recursively, we can instead compute the determinant of a much smaller matrix; for the example above with $M=4$, the absolute value of the determinant simplifies to the absolute value of a single entry ($|-1|$).
Indeed, if some input variable is copied to some output variable, then we can entirely avoid computing its row (and corresponding column) of the Jacobian, and the computational complexity reduces from $M^2$ to $(M-K)^2$ where $K$ is the number of input variables that were copied from some input variable.
The $\mathtt{@copy}$ statement in our differentiable programming language makes the set of input variables that were copied immediately available to the interpreter, which makes automating this optimization possible, as shown in \textproc{run-involution} in Algorithm~\ref{alg:auto-involutive-mcmc}.

Many involutive MCMC kernels update only a constant number of variables that does not depend on the size $N$ of the trace or the total number of continous keys $M$, and the other variables are copied over unchanged.
For example, consider the Jacobian for a split-merge reversible jump move~\citet{richardson1997bayesian}, which is implemented in Figure~\ref{fig:mixture}:
\includegraphics[width=\linewidth]{figures/sparse-jacobian.pdf}
Black squares indicate nonzero entries.
In this case, the size $N$ of the trace grows linearly both in the number of clusters and the number of data points, but the Jacobian determinant can be calculated from only the $6$-by-$6$ submatrix of the Jacobian that involves the parameters of the one cluster being split (or the two clusters being merged).
While a reasonable hand-coded implementation of this algorithm would likely perform this optimization as well, Algorithm~\ref{alg:auto-involutive-mcmc} automates it.

% TODO show an performance table of moves per second with and without the sparsity reduction (?)
\subsection{Incremental Computation of Model Density Ratio and Implicit Copies}

While it is possible to compute the ratio of densities in Equation~(\ref{eq:density-ratio}) by separately computing the four densities of the four traces, this scales linearly in the total number of random choices in the traces, because every random choice in each trace needs to be visited to compute the products in Equation~(\ref{eq:density-product}).
Often, the number of random choices in the auxiliary traces $y$ and $y'$ are constant size $O(1)$ whereas the number of random choices in the model traces $x$ and $x'$ is $O(N)$ where $N$ is the number of data points, or latent components
(see Figure~\ref{fig:mixture} for an example, where at most two clusters are affected by each application of the MCMC kernel).
In these cases, the ratio of model trace densities $p(x') / p(x)$ dominates the asymptotic running time of computing the density ratio of Equation~\ref{eq:density-ratio}.
However, due to conditional independencies in the model, the densities $p(x')$ and $p(x)$ often share common factors that cancel, which affords an opportunity for $O(1)$ computation of the ratio.
Gen's trace API includes an \emph{incremental update} operation~\citep{gen-paper}, which takes a previous trace $x$, and a partial trace $u$ containing the values of random choices that should be changed (or added if there is stochastic structure in the model), and returns a new trace $x'$.
This allows for $O(1)$ computation of $p(x') / p(x)$ when the modeling language runtime system is able to detect and exploit the cancellation.

If an address is present in the input model trace and is needed to form a complete output model trace but was not written to or copied to in by the function body, then it will be implicitly copied from the previous trace by the runtime implementation.
This significantly reduces the amount of code that has to be written when only a small subset of the model trace is being modified during the application of the involution MCMC move (which is common in applications of reversible jump MCMC).
As a simple example, if there are $N$ latent variables, and the move only updates 1 of them, then the involution needs to contain only $O(1)$ lines of code instead of $O(N)$ lines.

TODO: show an example


While it is possible to compute the ratio of densities in Equation~(\ref{eq:density-ratio}) by separately computing the four densities of the four traces, this scales linearly in the total number of random choices in the traces, because every random choice in each trace needs to be visited to compute the products in Equation~(\ref{eq:density-product}).
Often, the number of random choices in the auxiliary traces $y$ and $y'$ are constant size $O(1)$ whereas the number of random choices in the model traces $x$ and $x'$ is $O(N)$ where $N$ is the number of data points, or latent components
(see Figure~\ref{fig:mixture} for an example, where at most two clusters are affected by each application of the MCMC kernel).
In these cases, the ratio of model trace densities $p(x') / p(x)$ dominates the asymptotic running time of computing the density ratio of Equation~\ref{eq:density-ratio}.
However, due to conditional independencies in the model, the densities $p(x')$ and $p(x)$ often share common factors that cancel, which affords an opportunity for $O(1)$ computation of the ratio.
Gen's trace API includes an \emph{incremental update} operation~\citep{gen-paper}, which takes a previous trace $x$, and a partial trace $u$ containing the values of random choices that should be changed (or added if there is stochastic structure in the model), and returns a new trace $x'$.
This allows for $O(1)$ computation of $p(x') / p(x)$ when the modeling language runtime system is able to detect and exploit the cancellation.

If an address is present in the input model trace and is needed to form a complete output model trace but was not written to or copied to in by the function body, then it will be implicitly copied from the previous trace by the runtime implementation.
This significantly reduces the amount of code that has to be written when only a small subset of the model trace is being modified during the application of the involution MCMC move (which is common in applications of reversible jump MCMC).
As a simple example, if there are $N$ latent variables, and the move only updates 1 of them, then the involution needs to contain only $O(1)$ lines of code instead of $O(N)$ lines.

TODO: show an example

\section{A DYNAMIC CHECK FOR DETECTING BUGS}

Due to the automation described in the previous section, users of Gen can implement involutive MCMC algorithms by writing probabilistic programs for $p$ and $q$ and a differentiable program for the involution $f$, avoiding the need to derive and implement the accept/reject formula by hand. 
This eliminates certain classes of errors that could otherwise be difficult to root out in hand-coded implementations of MCMC algorithms. However, it is still of course possible to implement $p$, $q$, or $f$ incorrectly, introducing bugs that may invalidate the correctness proofs for the involutive MCMC algorithm.


Fortunately, the factorization of diverse algorithms into a common template, involving an explicitly represented model, auxiliary distribution, and involution, enables simple and automated debugging checks that can catch a wide variety of such errors dynamically. These checks are not complete, but anecdotally, we have found that they often alert users to subtle bugs in the design or implementation of an algorithm. The checks are summarized in Algorithm~\ref{alg:dynamic-check}.


\begin{algorithm}[h]
\begin{algorithmic}
\Procedure{imcmc-dynamic-check}{$p$, $q$, $f$}
    \State $x \sim p(\cdot)$ \Comment{Sample state from prior}
    \State $y \sim q_x(\cdot)$ \Comment{Sample auxiliary variables}
    \State $(x', y') \gets f(x, y)$ \Comment{Apply involution}
    \State {\bf assert} $p(x')q_{x'}(y') > 0$ \Comment{Support check}
    \State {\bf assert} $f(x', y') = (x, y)$ \Comment{Involution check}
    \State {\bf assert} $|\text{Rd}^{\textit{cont}}_{f,x,y}| = |\text{Wr}^{\textit{cont}}_{f,x,y}|$ \Comment{Dimension check}
\EndProcedure
\end{algorithmic}
\caption{Dynamic Check for Bugs}
\label{alg:dynamic-check}
\end{algorithm}

To test the user's algorithm, Gen first samples a model trace $x$ from the model prior $p$, and auxiliary randomness $y$ from the kernel $q_x$. It then runs three tests:

\begin{enumerate}
\item \textbf{Support check.} The \textit{support check} runs the involution $f$ on $(x, y)$ and checks that the resulting pair of traces, $(x', y')$, are within the set $Z$ of positive-density elements for $\pi$.

\item \textbf{Involution check.} The \textit{involution check} runs $f \circ f$ on $(x, y)$ and checks that the result is equal to $(x, y)$. If $f$ is an involution on $Z$, then this check will always succeed; if there is a set $\tilde{Z}$ of positive $\pi$-measure on which $f(f(z)) \neq z$ (i.e., $f$ is not an involution), then this check has positive probability of failing.

\item \textbf{Dimension check.} The \textit{dimension check} runs the involution $f$ on $(x, y)$ and records the sets of addresses $\text{Rd}_{f,x,y}^{\textit{cont}}$ and $\text{Wr}_{f,x,y}^{\textit{cont}}$ at which $f$ performs continuous reads and writes, respectively. It then checks that the sizes of these sets match. (Addresses with an $n$-dimensional Lebesgue measure as their reference measure, corresponding to vector-valued random choices, are unpacked into $n$ separate addresses for the purposes of this check.)
\end{enumerate}

These checks each catch qualitatively different bugs in user programs. We now give several examples.

\textit{Incorrectly transformed continuous variables.} Many bugs in the design or implementation of deterministic transformations of continuous variables are naturally detected by the involution check. Consider, for example, the Hamiltonian Monte Carlo algorithm~\citep{hmc}, which, as \citet{imcmc} observe, is an instance of the involutive MCMC framework. 
%$x$ is the model state, $y$ is the momentum, and the involution $f$ first runs a leapfrog integrator to obtain a new state $x'$ and final momentum $-y'$, then negates the final momentum and returns $(x', y')$. 
When applied to HMC, Gen's dynamic bug check involves:
%Gen's dynamic checks will uncover mathematical errors in the implementation of the leapfrog integrator, and will also detect a failure to perform the final negation of the momentum. In particular, the dynamic check involves 
(a) sampling a model state $x$ from the prior; (b) sampling a momentum $y$; (c) running the leapfrog integrator forward to get a new state $x'$ and new momentum $-y'$, (d) running the leapfrog integrator backward from state $x'$ with momentum $y'$, and (e) checking that this results in the state-momentum pair $x, -y$. If the momentum is not properly negated, or if the leapfrog integrator is incorrectly implemented, this check can fail.

As another, simpler example of this type of error, consider the \texttt{split\_params} and \texttt{merge\_params} functions invoked in Figure~\ref{fig:mixture}, as part of a reversible-jump MCMC kernel for learning a mixture of Gaussians with an unknown number of components. Considering only the $\mu$ parameter, suppose the \textit{split} move samples an auxiliary variable $u_1$ and computes $\mu_1 = \mu + u_1, \mu_2 = \mu - u_1$ as the means of the two new clusters. If the \textit{merge} move joins two clusters and assigns $\mu = \sqrt{\mu_1 \mu_2}$, there is a mismatch: a split move cannot be reversed by a corresponding merge, because in general, $\sqrt{(\mu+u_1)(\mu-u_1)} \neq \mu$. This error could be fixed either by changing the split to compute $\mu_1 = \mu u_1, \mu_2 = \frac{\mu}{u_1}$, or by changing the merge to compute $\mu = \frac{\mu_1 + \mu_2}{2}$.

As a final, rather different example in this class, suppose approximate inverses $F_\theta, G_\theta : \mathbb{R}^d \rightarrow \mathbb{R}^d$ are learned neural networks trained via a Cycle GAN objective~\citep{cyclegan} to translate between the latent spaces of two models in a Bayesian model selection problem. A user might implement the following involution:

\begin{center}
\begin{tabular}{c}
{\begin{lstlisting}[basicstyle=\small\ttfamily]
@tracefn h from (tr1, tr2) to (tr3, tr4)
   which_model = @read(tr1, :model, :discrete)
   if which_model == 1
      z = @read(tr1, :z, :continuous)
      z_in_model_2 = F(z)
      @write(tr3, :z, z_in_model_2, :continuous)
      @write(tr3, :model, 2, :discrete)
   else
      z = @read(tr1, :z, :continuous)
      z_in_model_1 = G(z)
      @write(tr3, :z, z_in_model_1, :continuous)
      @write(tr3, :model, 1, :discrete)
   end
end
\end{lstlisting}}
\end{tabular}
\end{center}

However, even though $F_\theta$ and $G_\theta$ are trained with
an objective that encourages $F_\theta(G_\theta(z)) \approx z$, 
this relationship is not exact equality, so the involutive MCMC
framework cannot be directly applied, and the involution check
will fail. This error could be fixed by sampling a proposed value
\textit{near} $F_\theta(z)$ or $G_\theta(z)$, rather than directly applying $F_\theta$
and $G_\theta$ to $z$.

\textit{Discrete logic errors.} Another common class of errors is 
for the discrete logic of an involution to be flawed. Consider the following incorrect 
implementation of a \textit{birth-death} move for the mixture model in Figure~\ref{fig:mixture}, which either adds a new mixture component or selects an existing one
at random to delete:

\begin{center}
\begin{tabular}{c}
{\begin{lstlisting}[basicstyle=\small\ttfamily]
@gen function q(trace)
  current_k = trace[:k]
  is_birth ~ bernoulli(current_k == 1 ? 1.0 : 0.5)
  if is_birth
    new_mu ~ normal(0, 10)
    new_var ~ inv_gamma(1, 10)
  else
    deletion_idx ~ uniform_discrete(1, current_k)
  end
end

@tracefn h from (tr1, tr2) to (tr3, tr4)
   is_birth = @read(tr2, :is_birth, :discrete)
   @write(tr4, :is_birth, !is_birth, :discrete)
   k = @read(tr1, :k, :discrete)
   weights = @read(tr1, :weights, :continuous)
   if is_birth
     @write(tr3, :k, k+1, :discrete)
     new_mu = @read(tr2, :new_mu, :continuous)
     new_var = @read(tr2, :new_var, :continuous)
     @write(tr3, (:mu, k+1), new_mu, :continuous)
     @write(tr3, (:var, k+1), new_var, :continuous)
     new_weights = add_weight(weights)
     @write(tr4, :deletion_idx, k+1, :discrete)
   else
     idx = @read(tr2, :deletion_idx, :discrete)
     @copy(tr1, (:mu, idx), tr4, :new_mu)
     @copy(tr1, (:var, idx), tr4, :new_var)
     for i in (idx+1):k
       @copy(tr1, (:mu, i), tr3, (:mu, i-1))
       @copy(tr1, (:var, i), tr3, (:var, i-1))
     end
     @write(tr3, :k, k-1, :discrete)
     new_weights = delete_weight(weights, idx)
   end
   @write(tr3, :weights, new_weights, :continuous)
end
\end{lstlisting}}
\end{tabular}
\end{center}

The flaw in this implementation is that although the death move can 
delete any of the $k$ mixture components, the birth move can only add
a new component to the \textit{end} (index $k+1$), so the move is not
reversible. Gen's involution check will discover that the deletion of a
component with index $i < k$ is not reversed by a corresponding birth move,
and will thus raise an error.

\textit{Other miscellaneous errors.} When implementing distributions as probabilistic programs, it is also possible for users to make more mundane errors, such as spelling the name of a random choice inconsistently, or characterizing random choices using the wrong \texttt{type} tags (\texttt{:continuous} and \texttt{:discrete}). Such errors can be difficult to detect statically, because the addresses at which a probabilistic program makes random choices, and the distributions of those choices, may change from sample to sample. (Previous work has explored static analyses based on types~\citep{popltraces} and abstract interpretation~\citep{verified_svi}, but these each work on limited subsets of the programs that Gen's full modeling language permits, and it is often precisely these more complex programs that require the flexibility of the involutive MCMC framework in the first place.) Gen's dynamic support and dimension checks can help to detect bugs like these. For example, if the involution $f$ writes to a misspelled address, the support check will determine that the resulting trace's density is 0.

% TODO show an example of the type of bug it can detect (an edge case?)

\textbf{Dynamic checks during inference.} These dynamic assertions can also be run during inference, at each application of the transition kernel. This can be useful to catch bugs that only occur in regions of the state space with low prior mass (but perhaps high posterior mass). When enabled, we can run dynamic checks after each application of the kernel, and when they fail, write to a debugging log and reject the proposed new state. As it turns out, the kernel induced by this procedure is still stationary for $p$:

\begin{lemma}
Let $p$ and $q_x$ be model and auxiliary densities as above, but suppose $f : \mathcal{D} \times \mathcal{D} \rightarrow \mathcal{D} \times \mathcal{D}$ may not be an involution on $Z$.  Trace-based involutive MCMC with dynamic checks enabled, rejecting whenever such a check fails, still yields a kernel that is stationary for $p$.
\end{lemma}
\begin{proof}
Let $R = \{x \in Z \mid f(f(x)) = x \wedge \pi(f(x)) > 0\}$, and let $h(x) := \mathbf{1}[x \in R]f(x) + \mathbf{1}[x \not\in R]x$. Then $h$ is an involution on $Z$, and trace-based involutive MCMC with $p$, $q_x$, and $h$ yields a stationary kernel. But this kernel is the same one induced by using $f$ with dynamic checks. For $x$ on which dynamic checks succeed, $h$ is equivalent to $f$. For $x$ on which dynamic checks fail, $h$ is equivalent to the identity; thus, accepting a move produced by $h$ is equivalent to rejecting.  
\end{proof}

\section{EXAMPLES}

\subsection{Reversible Jump MCMC}
Reversible jump MCMC~\citep{green1995reversible,hastie2012model} is a special case of involutive MCMC, and 
the implementation of reversible jump MCMC kernels can be automated using the probabilistic and differentiable programming languages presented in this paper.
We now review reversible jump MCMC, then show how it can be automated using the techniques presented earlier, and give an example.

The reversible jump MCMC framework involves a set of `models' $h \in \mathcal{H}$, and a prior distribution on models $p(h)$.
For each model, there is a latent continuous parameter vector $\theta_h \in \mathbb{R}^{n(h)}$ where $n(h)$ is the dimension of model $h$, and a likelihood function $L_{D,h}(\theta_h)$ for each $h$ given data $D$.
The latent state $x$ is a pair $(h, \theta_h)$ of model and continuous parameter.
There is a set of \emph{move types} $\mathcal{M}$.
Each move type $m \in \mathcal{M}$ is associated with an unordered pair of models $(h_1, h_2)$ and a dimensionality $d(m)$ such that $d(m) \ge n(h_1)$ and $d(m) \ge n(h_2)$ (zero, one, or more than one move types may be associated with a given pair of models).
For each latent state $x = (h, \theta_h)$, there is a probability distribution $q_{x}(m)$ on move types such that $q_{x}(m) > 0$ implies that $h$ is one of the models for move type $m$.
For each move type $m \in \mathcal{M}$ between $h_1$ and $h_2$ there is a pair of continuously differentiable bijections $g_{m, h_1 \to h_2} : \mathbb{R}^{d(m)} \to \mathbb{R}^{d(m)}$ and $g_{m, h_2 \to h_1} := g_{m, h_1 \to h_2}^{-1}$, and a pair of proposal densities $q_{m,h_1 \to h_2}(u_{h_1 \to h_2})$ and $q_{m,h_2 \to h_1}(u_{h_2 \to h_1})$ where $u_{h_1 \to h_2} \in \mathbb{R}^{d(m) - n(h_1)}$ and $u_{h_2 \to h_1} \in \mathbb{R}^{d(m) - n(h_2)}$.
A proposal is made from state $x = (h, \theta_h)$ by (i) sampling a move type $m \sim q_{x}(\cdot)$, and (ii) sampling continuous variable $u \sim q_{m,h \to h'}(\cdot)$ for $(h, h')$ associated with $m$, and (iii) computing $(\theta_{h}', u') := g_{m,h \to h'}(\theta_h, u)$, and proposing new state $x' = (h', \theta_h')$.
The move is accepted with probability:
\begin{equation}
{
\min\left\{ 1,
\frac{p(h')}{p(h)} \frac{p_{h'}(\theta_{h'})}{p_h(\theta_h)} \frac{L_{D,h'}(\theta_h')}{L_{D,h}(\theta_h)}
\frac{q_{x'}(m)}{q_{x}(m)}
\frac{q_{m,h' \to h}(u)}{q_{m,h \to h'}(u)}
\right\}
}
\end{equation}

To represent reversible jump MCMC using involutive MCMC implemented with probabilistic programs, we write a probabilistic program $\mathcal{P}$ that encodes the space of models $\mathcal{H}$, the prior distribution on models, $p(h)$, the per-model priors $p_h(\theta_h)$ and the per-model likelihoods $L_{D,h}(\theta_h)$.
The set of all models $h$ corresponds to the set of all pairs $(K_\mathcal{P}, \mathbf{d}_\mathcal{P})$ where $K_\mathcal{P}$ represent possible trace structures (i.e. control-flow paths through $\mathcal{P}$) and $\mathbf{d}_\mathcal{P}$ are the set of assignments to discrete random choices made by $\mathcal{P}$.
The per-model continuous parameters $\theta$ correspond to continuous random choices $\mathbf{c}_\mathcal{P}$.
% TODO explain the likelihood
An auxiliary probabilistic program $\mathcal{Q}$ encodes both the probability distribution on moves types using discrete random choices and possibly stochastic control flow ($(K_\mathcal{Q}, \mathbf{d}_\mathcal{Q})$), and the per-move-type probability densities on $u$ using continuous random choices $\mathbf{c}_\mathcal{Q}$.
The involution $f$ factors into an (i) involution $f_1$ on pairs $i = ((K_\mathcal{P}, \mathbf{d}_\mathcal{P}), (H_\mathcal{Q}, \mathbf{d}_\mathcal{Q}))$ that defines the association between move types $\mathcal{M}$ and the model pairs ($h_1, h_2$); and (ii) a family of bijections $f_{1,i}$ on the space of pairs $(\mathbf{c}_\mathcal{P}, \mathbf{c}_\mathcal{Q})$ of continuous random choices for both programs for fixed values of the discrete random choices and fixed trace structure.

Figure~\ref{fig:mixture} shows a split-merge reversible jump kernel for an infinite Gaussian mixture model~\citep{richardson1997bayesian} implemented using the probabilistic and differentiable programming languages described in this paper.
Figure~\ref{fig:mixture}(b) shows the infinite Gaussian mixture model, specified as a probabilistic program $\mathcal{P}$.
The program takes the number of data points as input, then samples the number of clusters from a Poisson distribution, then samples cluster parameters and mixture proportions, and finally samples the data points from the resulting finite mixture.
Figure~\ref{fig:mixture}(c) shows the auxiliary probabilistic program $\mathcal{Q}$ for the split-merge kernel.
This program takes a trace of the model program as input, and randomly decides whether to split a cluster and increase the number of clusters by one or merge two clusters and decrease the number of clusters by one.
Then, the program randomly picks which cluster to split, or which clusters to merge.
This kernel always merges the last cluster with a random other cluster; for ergodicity the move can be composed with a simple move (that has acceptance probability $1$) that swaps a random cluster with the last cluster.
If a split is chosen, then the program also samples the three degrees of freedom necessary to generate the new parameters for the clusters in an invertible manner.
Figure~\ref{fig:mixture}(d) shows a differentiable program specifying the involution for the split-merge kernel, and Figure~\ref{fig:mixture}(f) shows graphically how this involution acts on pairs of traces.
The yellow section (1) defines an involution $f_1$ on the discrete random choices that specifies that (i) the \texttt{split} choice should be flipped (so that split moves are always mapped to merge moves and vice versa) and that (ii) the number of clusters should be increased by one for a split move and decreased by one for a merge move, and (iii) which merged cluster corresponds to which split clusters.
The green section (2) specifies the continuous bijections that govern the transformation of continuous random choices during split moves and the purple section (3) specifies the inverses of these bijections, which govern the transformation of continuous choices during merge moves.

\subsection{State-Dependent Mixture Proposal}

State-dependent mixture proposal.
Depending on the current state of the model, a different mixture distribution is used for the proposal.
Implementing such a move requires computing the mixture probability under the forward move and under the reverse move, which may differ.

$q_x(m)$ -- the mixture distribution

$q_m(x')$ -- the proposal we are mixing over

The first part of the auxiliary probabilistic program $Q$ determines which proposal to apply by sampling from a mixture distribution.
Here, the program picks a random node in the tree, by doing a stochastic walk of the tree that terminates at the chosen node.
\begin{center}
\begin{tabular}{c}
{\begin{lstlisting}[basicstyle=\small\ttfamily]
prev_cov_function = trace[:cov_function]
path ~ walk_tree(prev_cov_function, ..)
\end{lstlisting}}
\end{tabular}
\end{center}
The first part of the involution copies the random choices corresponding to the mixture from the input auxiliary trace to the output auxiliary trace.
\begin{center}
\begin{tabular}{c}
{\begin{lstlisting}[basicstyle=\small\ttfamily]
@copy(q_in, :path, q_out, :path)
\end{lstlisting}}
\end{tabular}
\end{center}

The code that walks the tree uses the following recursion, which results in a probability distribution that assigns exponentially lower probability to nodes that are deeper in the tree.
\begin{center}
\begin{tabular}{c}
{\begin{lstlisting}[basicstyle=\small\ttfamily]
if ({:done} ~ bernoulli(0.5))
  return path
elseif ({:recurse_left} ~ bernoulli(0.5))
  path = (path..., :left_node)
  return ({:left} ~ walk_tree(node.left, path))
else
  path = (path..., :right_node)
  return ({:right} ~ walk_tree(node.right, path))
end
\end{lstlisting}}
\end{tabular}
\end{center}
The resulting mixture distributions for two trees are:
\begin{center}
\includegraphics[width=0.8\linewidth]{figures/biased-tree-distribution.pdf} % TODO improve quality
\end{center}
Because the mixture is specified using a probabilistic program, it is straightforward to modify the program to define a different mixture distribution.
The code below specifies a mixture distribution that is uniform over all nodes in the tree.
\begin{center}
\begin{tabular}{c}
{\begin{lstlisting}[basicstyle=\small\ttfamily]
n1 = size(node.left); n2 = size(node.right)
if ({:done} ~ bernoulli(1 / (1 + n1 + n2)))
  return path
elseif ({:recurse_left} ~ bernoulli(n1 / (n1+n2))
  path = (path..., :left_node)
  return ({:left} ~ walk_tree(node.left, path))
else
  path = (path..., :right_node)
  return ({:right} ~ walk_tree(node.right, path))
end
\end{lstlisting}}
\end{tabular}
\end{center}
The resulting distributions are:
\begin{center}
\includegraphics[width=0.8\linewidth]{figures/unbiased-tree-distribution.pdf}
\end{center}
Note that in the first case, the ratio of mixture probabilities is either $1$, $0.5$, or $2$ depending on whether the previous and new subtrees are leaf or internal nodes.
In the second case, the ratio of mixture probabilities is the ratio of sizes of the two trees.
%Automating the computation of the mixture probabilities




The rest of the kernel specifies what happens for each chosen node.
The second part of the auxiliary probabilistic program $Q$ implements a common motif for Metropolis-Hastings algorithms, where the proposal samples new values for some random choices:
\begin{center}
\begin{tabular}{c}
{\begin{lstlisting}[basicstyle=\small\ttfamily]
new_subtree ~ cov_function_prior()
\end{lstlisting}}
\end{tabular}
\end{center}
and the involution swaps the old value with the newly proposed value:
\begin{center}
\begin{tabular}{c}
{\begin{lstlisting}[basicstyle=\small\ttfamily]
@copy(p_in, subtree_kddress, q_out, :new_subtree)
@copy(q_in, :new_subtree, p_out, subtree_kddress)
\end{lstlisting}}
\end{tabular}
\end{center}
Here the values happen to be trees that themselves have a random number of random choices, but the same motif is also used in simpler applications of Metropolis-Hastings.


Here, the proposal we are mixing over is easy to implement -- it involvs resampling a subtree from the prior, so the Jacobian is 1 and there is cancellation between the model and the proposal.

But computing the mixture probabilities is complex, because the mixture is a mixture of either $n_1$ or $n_2$ elements, which depends on the size of the tree.

Show the mixture probabilities in math notation?
If both subtrees not leaf nodes, then the probabilities are the same.
If both subtrees are leaf nodes, then the probabilities are different.
If one subtree is a leaf node and the other is an internal node then the ratio is either $0.5$ or $2$ respectively.
\begin{equation}
q
\end{equation}

TODO: relate to `resimulation Metropolis-Hastings' in general-purpose probabilistic programs.

Of course, it is straightforward to replace the prior with a custom data-driven proposal distribution on subtrees.

\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/structure-learning.pdf}
    \caption{
A mixture kernel implemented using involutive MCMC in Gen, applied to infer the covariance function of a Gaussian process.
The prior on covariance functions is based on a probabilistic context-free grammar.
Each component kernel in the mixture replaces a subtree of the covariance function parse tree with a new subtree.
The mixture kernel chooses a random subtree to replace via a random walk on the parse tree.
The mixture kernel is composed from three Gen programs:
(1) a probabilistic program $\mathtt{p}$ encoding the generative model (shown in a),
(2) a probabilistic program $\mathtt{q}$ encoding an auxiliary probability distribution (shown in b), and
(3) a differentiable program $\mathtt{h}$ that encodes an involution (shown in d).
}
    \label{fig:structure-learning}
\end{figure*}


\subsubsection*{Acknowledgements}
All acknowledgments go at the end of the paper, including thanks to reviewers who gave useful comments, to colleagues who contributed to the ideas, and to funding agencies and corporate sponsors that provided financial support.

\bibliography{references} 

\clearpage
\onecolumn
\section*{APPENDIX}

%\subsection{Distributions on traces}
%% TODO rewrite this section..
%Define target density $\pi$ (XXX below it is called $p$, fix this) on the joint space $X \times U$, where $X$ are traces of the model and $X$ are traces of the proposal, in terms of the density $p(x)$ and the family of densities $q_x(u)$ as $\pi(x, u) := p(x) q_u(x)$.
%
%% TODO rename the joint target density to \pi below
%We want to show stationarity with respect to $\pi$, using stationarity of the involution with respect to the joint density (below).
%\begin{equation}
%\int_X p(x) \ell_x(A) \mu(dx) = p(A) \mbox{ for all } A \in \Sigma
%\end{equation}
%where $\ell_x(A)$ is the probability of transitioning into set $K$ from $x$, and is given by:
%\begin{equation}
%\ell_x(A) := \int_U k_{(x, u)}(A \times U) \mu(du)
%\end{equation}
%where $k_{(x, u)}$ is the measure on $X \times U$ that is induced by applying the involution $h$ to the state $(x, u)$.
% TODO checkme


\subsection{Derivation of the pushforward Radon-Nikodym derivative for a special case} \label{sec:radon-nikodym-special-case}
Implementing Algorithm~\ref{alg:involutive-mcmc} requires computing the Radon-Nikodym derivative $d (\mu \circ f^{-1}) / d \mu$.
This section derives that function for the special case in which the involution $f$ can be factored into an involution on a countable set $I$ and a family of bijections on $\mathbb{R}^{n_i}$ for some $n_i$ for each $i \in I$.
Suppose $Z = \{(i, \mathbf{x}) : i \in I, \mathbf{x} \in \mathbb{R}^{n_i}\}$.
Suppose $f_1$ is an involution on $I$ and $n_i = n_{f_1(i)}$ and $f_2$ is a family of continuously differentiable bijections indexed by $i \in I$, such that $f_{2,i} : \mathbb{R}^{n_i} \to \mathbb{R}^{n_i}$.
Also suppose that $f_{2,i} = f_{2,f_1(i)}^{-1}$ for all $i \in I$. That is,
\begin{equation}
f_{2,i}(f_{2,f_1(i)}(\mathbf{x})) = \mathbf{x} \mbox{ for all } \mathbf{x} \in \mathbb{R}^{n_i} \mbox{ and all } i \in I
\end{equation} 
Then, $f : Z \to Z : (i, \mathbf{x}) \mapsto (f_1(i), f_{2,i}(\mathbf{x}))$ is an involution because:
\begin{equation}
f(f(i, \mathbf{x})) = f(f_1(i), f_{2,i}(\mathbf{x})) = (f_1(f_1(i)), f_{2,f_1(i)}(f_{2,i}(\mathbf{x}))) = (i, \mathbf{x})
\end{equation}
Let $\Sigma_n$ and $\mu_n$ denote the Lebesgue $\sigma$-algebra and Lebesgue measure on $\mathbb{R}^n$, respectively.
Let $\Sigma \subset \mathcal{P}(Z)$ be the $\sigma$-algebra of sets of the form $\cup_{i \in I} \{(i, \mathbf{x}) : \mathbf{x} \in K_i\}$ for some $K_i \in \Sigma_{n_i}$ for each $i \in I$.
%Let $\Sigma$ be the $\sigma$-algebra on $Z$ generated by the sets $G := \{ \{(i, \mathbf{x}) : \mathbf{x} \in A\} : i \in I, A \in \Sigma_{n_i} \}$.
%Note that the sets $G$ form a $\pi$-system:
%\begin{align}
%\{(i, \mathbf{x}) : \mathbf{x} \in A\} \cap \{(j, \mathbf{x}) : \mathbf{x} \in B\} = \varnothing = \{(i, \mathbf{x}) : \mathbf{x} \in \varnothing \} \in G \mbox{ for } i \ne j\\
%\{(i, \mathbf{x}) : \mathbf{x} \in A\} \cap \{(i, \mathbf{x}) : \mathbf{x} \in B\} = \{(i, \mathbf{x}) : \mathbf{x} \in A \cap B\} \in G \mbox{ because } A \cap B \in \Sigma_{n_i}
%\end{align}
Let $\mu$ denote the measure on measurable space $(Z, \Sigma)$ given by:%, uniquely defined by its value on the sets $G$:
\begin{equation}
\mu(\cup_{i \in I} \{(i, \mathbf{x}) : \mathbf{x} \in K_i\}) := \sum_{i \in I} \mu_{n_i}(K_i)
\end{equation}
We wish to show that the Radon-Nikodym derivative of the pushforward of $\mu$ by $f$ with respect to $\mu$, evaluated at $(i, \mathbf{x})$, is the absolute value of the Jacobian (determinant) of the function $f_{2,i}$ evaluated at $\mathbf{x}$, which is denoted $(J f_{2,i})(\mathbf{x})$:
\begin{equation}
\frac{d (\mu \circ f^{-1})}{d \mu}(i, \mathbf{x})
= \left| (Jf_{2,i})(\mathbf{x})\right|
\end{equation}
Consider $(\mu \circ f^{-1})(A)$ for $K \in \Sigma$:
\begin{align}
(\mu \circ f^{-1})(\cup_{i \in I} \{ (i, \mathbf{x}) : \mathbf{x} \in K_i \})
&= \mu(f^{-1}(\cup_{i \in I} \{ (i, \mathbf{x}) : \mathbf{x} \in K_i \}))\\
&= \mu(\cup_{i \in I} f^{-1}(\{ (i, \mathbf{x}) : \mathbf{x} \in K_i \}))\\
&= \mu(\cup_{i \in I} \{ (f_1(i), \mathbf{x}) : \mathbf{x} \in f_{2,i}(K_i) \})\\
&= \sum_{i \in I} \mu_{n_i}(f_{2,i}(K_i))
\end{align}
It suffices to show that for all $K \in \Sigma$:
\begin{equation}
\int_K \left| (Jf_{2,i})(\mathbf{x})\right| \mu(dz) = \sum_{i \in I} \mu_{n_i}(f_{2,i}(K_i))
\end{equation}
Expanding the left-hand side:
\begin{align}
\int_K \left| (Jf_{2,i})(\mathbf{x})\right| \mu(dz)
= \sum_{i \in I} \int_{K_i} \left| (Jf_{2,i})(\mathbf{x})\right| \mu_{n_i}(d \mathbf{x}) % TODO how to justify this? it seems obvious
= \sum_{i \in I} \mu_{n_i}(f_{2,i}(K_i)) % Borgachev Theorem 4.7.1 
\end{align}
where the final step uses Borgachev Theorem 3.7.1 with $g := 1$, and $F := f_{2,i}$.

\subsection{Proof of detailed balance for involution} \label{sec:involution-detailed-balance}

\begin{lemma}
Given $\sigma$-finite measures $(X_P, \Sigma_P, \mu_P)$ and $(X_Q, \Sigma_Q, \mu_Q)$,
if $X \in \Sigma_P \otimes \Sigma_Q$ then $\Sigma = \{A \in \Sigma_P \otimes \Sigma_Q : K \subseteq X\}$ is a $\sigma$-algebra on $X$, and $\mu : \Sigma \to [0, \infty)$ given by $\mu(A) := (\mu_P \times \mu_Q)(A)$ is $\sigma$-finite measure on measurable space $(X, \Sigma)$.
\end{lemma}
\begin{proof}
TODO: write out the detailed steps, proving each property of a $\sigma$-algebra%$ TODO
\end{proof}

\begin{lemma}
$\pi : X \to [0, \infty)$ is a probability density with respect to $\mu$ and the measure induced by $\pi$ and the measure $\mu$ are mutually absolutely continuous 
\end{lemma}
\begin{proof}
% TODO need to show that pi is measurable by the product measure?
\begin{equation}
\int_X \pi(x) \mu(dx) = \int_{X_P \times X_Q} \pi(x) (\mu_P \times \mu_Q)(dx) = \int_{X_P} p(t) \left( \int_{X_Q} q_t(u) \mu_Q(du) \right) \mu_P(dt) = 1
\end{equation}

%(note that $\mu$ is $\sigma$-finite since $\mu_P \times \mu_Q$ is $\sigma$-finite. % TODO: prove this 
%Suppose that $\pi$ is a probability density with respect to $\mu$. % TODO is this guaranteed?
\end{proof}


\citet{tierney1998note} gives a class of MCMC kernels based on involutions that satisfy detailed balance.
We reproduce the result in our notation:
\begin{lemma}[Detailed balance for involution move~\citep{tierney1998note}] \label{lemma:tierney-involution}
Let $(Z, \Sigma, \pi)$ denote a measure space.
Suppose $f$ is a one-to-one function from $Z$ onto $Z$ such that $f^{-1} = f$.
Consider the probability kernel $k$ defined by $k_z(A) := [f(z) \in A] \alpha(z, f(z)) + [z \in A] (1 - \alpha(z, f(z)))$ (where $\alpha(z, f(z))$ gives the probability of accepting a proposed transition from $z$ to $f(z)$).
Let $\nu(dz) := \pi(dz) + (\pi \circ f^{-1})(dz)$.
Let $h(z)$ be a density for $\pi$ with respect to $\nu$.
Let $K := \{z \in Z : h(z) > 0 \mbox{ and } h(f(z)) > 0\}$.
$k$ satisfies detailed balance with respect to $\pi$ if and only if:
\begin{enumerate}
\item $\alpha(z, f(z)) = 0$ for $\pi$-almost all $z \not \in K$
\item $\alpha(z, f(z)) \frac{h(z)}{h(f(z))} = \alpha(f(z), z)$
\end{enumerate}
\end{lemma}

Now we apply Lemma~\ref{lemma:tierney-involution} to our setting where $\pi$ is $\sigma$-finite, there exists a $\sigma$-finite reference measure $\mu$ for measurable space $(Z, \Sigma)$ such that $\pi$ is mutually absolutely continuous with respect to $\mu$, and where the pushforward of $\mu$ by $f$, denoted $\mu \circ f^{-1}$, is absolutely continuous with respect to $\mu$.
%(One step in the proof---Equation~\ref{eq:mu-is-absolutely-continuous-with-respect-to-nu}---will also require that $\mu$ is also absolutely continuous with respect to $\pi$, which is possible if we restrict $Z$ to the support of $\pi$, $\{z : (d \pi / d \mu)(z) > 0\}$, which must be in the $\sigma$-algebra $\Sigma$).

In our setting, $\alpha$ is defined as:
\begin{equation}
\alpha(z, f(z)) := \mbox{min}\left\{1, \frac{\frac{d \pi}{d \mu}(f(z))}{\frac{d \pi}{d \mu}(z)} \cdot \frac{d (\mu \circ f^{-1})}{d \mu}(z)\right\}
\end{equation}
This definition of $\alpha$ satisfies:
\begin{equation}
\alpha(z, f(z)) \frac{\frac{d \pi}{d \mu}(z)}{\frac{d \pi}{d \mu}(f(z))} \cdot \left( \frac{d (\mu \circ f^{-1})}{d \mu} (z)\right)^{-1}= \alpha(f(z), z)
%\frac{\alpha(z, f(z))}{\alpha(f(z), z)} = \frac{\pi(T(z))}{\pi(z)} \left( \frac{d (\mu \circ T^{-1})}{d \mu} (z) \right)
\end{equation}
Therefore, to apply Lemma~\ref{lemma:tierney-involution}, it suffices to show $\pi$ has density with respect to $\nu$ (denoted $h(z)$) such that:
\begin{equation}
\frac{h(z)}{h(f(z))} = \frac{\frac{d \pi}{d \mu}(z)}{\frac{d \pi}{d \mu}(f(z))} \left( \frac{d (\mu \circ f^{-1})}{d \mu} (z)\right)^{-1}
\end{equation}
Since $\pi$ and $\pi \circ f^{-1}$ are both absolutely continuous with respect to $\mu$, $\nu$ is also absolutely continuous with respect to $\mu$, and has density:
\begin{equation}
\frac{d \nu}{d \mu}(z) = \frac{d \pi}{d \mu}(z) + \frac{d (\pi \circ f^{-1})}{d \mu}(z) 
\end{equation}
$\pi$ is absolutely continuous with respect to $\nu$, and therefore:
\begin{equation}
\frac{d \pi}{d \mu}(z) = \frac{d \pi}{d \nu}(z) \cdot \frac{d \nu}{d \mu}(z)
\end{equation}
Because $(d \pi / d \mu)(z) > 0$ for all $z \in Z$, $(d \nu / d \mu)(z) > 0$ for all $z \in Z$.
Therefore,
\begin{equation}
h(z)
:= \frac{d \pi}{d \nu}(z)
= \frac{\frac{d \pi}{d \mu}(z)}{\frac{d \nu}{d \mu}(z)}
\end{equation}
Therefore:
\begin{equation}
\frac{h(z)}{h(f(z))} = \frac{\frac{d \pi}{d \mu}(z)}{\frac{d \pi}{d \mu}(f(z))} \cdot \frac{\frac{d \nu}{d \mu}(f(z))}{\frac{d \nu}{d \mu}(z)}
\end{equation}
It suffices to show that:
\[
\frac{\frac{d \nu}{d \mu}(f(z))}{\frac{d \nu}{d \mu}(z)} = \left(\frac{d (\mu \circ f^{-1})}{d \mu}(z)\right)^{-1}
\]

First, we prove a Lemma:
\begin{lemma} \label{lemma:reference-measure-pushforward}
If $(Z, \Sigma)$ is a measurable space and $f : Z \to Z$ is a measurable function that is an involution, $\nu$ and $\mu$ are $\sigma$-finite measures such that $\nu$ is absolutely continuous with respect to $\mu$, and such that the pushforward measures $\nu \circ f^{-1}$ and $\mu \circ f^{-1}$ are both $\sigma$-finite, then
$\nu \circ f^{-1}$ is absolutely continuous with respect to $\mu \circ f^{-1}$ and
\begin{equation}
\frac{d (\nu \circ f^{-1})}{d (\mu \circ f^{-1})}(z) = \frac{d \nu}{d \mu}(f(z))
\end{equation}
\end{lemma}
\begin{proof}
First, $\nu \circ f^{-1}$ is absolutely continuous with respect to $\mu \circ f^{-1}$ because
$(\mu \circ f^{-1})(A) = 0$ implies $\mu(f^{-1}(A)) = 0$ implies $\nu(f^{-1}(A)) = 0$ implies $(\nu \circ f^{-1})(A) = 0$.
To show that $z \mapsto (d \nu / d \mu)(f(z))$ is the Radon-Nikodym derivative $d (\nu \circ f^{-1}) / d (\mu \circ f^{-1})$, it suffices to show that for all $K \in \Sigma$:
\begin{equation}
\int_K \left( \frac{d \nu}{d \mu} (f(z)) \right) ( \mu \circ f^{-1} )(dz) = (\nu \circ f^{-1})(A) := \nu(f^{-1}(A))
\end{equation}
Applying Theorem 3.6.1 in Bogachev with $Y := K$, $y := z$, $x := z'$, $X := f^{-1}(A)$, and $g(y) := (d\nu / d\mu)(f(y))$:
\begin{align}
\int_K \left( \frac{d \nu}{d \mu} (f(z)) \right) ( \mu \circ f^{-1} )(dz)
&= \int_Y g(y) ( \mu \circ f^{-1} )(dy)\\
&= \int_X g(f(x)) \mu(dx) \;\;\;\; [\mbox{Bogachev Theorem 3.6.1}]\\
&= \int_{f^{-1}(A)} (d\nu / d\mu)(f(f(z'))) \mu(dz')\\
&= \int_{f^{-1}(A)} (d\nu / d\mu)(z') \mu(dz')\\
&= \int_{f^{-1}(A)} \nu(dz')
= \nu(f^{-1}(A))
\end{align}
% NOTE Bogachev's theorem uses domains of integration which are the whole
% sample spaces for the two sigma algebras.  I think that the theorem should
% also apply to any measurable sets A and T(A) because one can construct a
% sigma algebra and measure that are restricted to to any nonempty measurable
% set.

\end{proof}

Now, note that $\nu$ and $\nu \circ f^{-1}$ are the same measure:
\begin{align}
\nu(A) &= \pi(A) + \pi'(A) = \pi(A) + \pi(f^{-1}(A))\\
(\nu \circ f^{-1})(A) &= \pi(f^{-1}(A)) + \pi(f^{-1}(f^{-1}(A))) = \pi(f^{-1}(A)) + \pi(A)
\end{align}
Therefore,
\[
\frac{d (\nu \circ f^{-1})}{d \nu}(z) = 1 \mbox{ for all } z
\]
Expanding $d(\nu \circ f^{-1}) / d \nu$ using the chain rule:
\begin{align}
1 &= \frac{d (\nu \circ f^{-1})}{d \nu}(z)\\
&=   \frac{d (\nu \circ f^{-1})}{d (\mu \circ f^{-1})}(z) \cdot
    \frac{d (\mu \circ f^{-1})}{d \mu}(z) \cdot
    \frac{d \mu}{d \nu}(z) \label{eq:mu-is-absolutely-continuous-with-respect-to-nu}\\
&= \frac{d \nu}{d \mu}(f(z)) \cdot \frac{d (\mu \circ f^{-1})}{d \mu}(z) \cdot \frac{d \mu}{d \mu}(z) \;\;\;\; [\mbox{Lemma~\ref{lemma:reference-measure-pushforward}}]\\
&= \frac{d \nu}{d \mu}(f(z)) \cdot \frac{d (\mu \circ f^{-1})}{d \mu}(z) \cdot \frac{1}{\frac{d \nu}{d \mu}(z)}\\
\left(\frac{d (\mu \circ f^{-1})}{d \mu}(z)\right)^{-1} &= \frac{\frac{d \nu}{d \mu}(f(z))}{\frac{d \nu}{d \mu}(z)}
\end{align}

\subsection{Proof of stationarity for involution} \label{sec:involution-is-stationary}
Detailed balance of the the involution kernel with respect to the measure induced by $\pi$ implies:
\begin{equation}
\int_B \pi(z) k'_z(A) \mu(dz) = \int_K \pi(z) k'_z(B) \mu(dz) \;\; \mbox{ for all } K, B \in \Sigma
\end{equation}
Stationarity with respect to $\pi$ follows by substituting $Z$ for $B$:
\begin{align}
\int_Z \pi(z) k'_z(A) \mu(dz) &= \int_K \pi(z) k'_z(Z) \mu(dz) = \int_K \pi(z) \mu(dz) \;\; \mbox{ for all } A \in \Sigma\\
\end{align}

\subsection{Proof of stationarity for end-to-end kernel} \label{sec:involutive-mcmc-is-stationary}
We are given that the involution is stationary with respect to (the measure induced by) $\pi(x, u) := p(x) q_x(u)$:
\begin{equation}
\int_Z k'_z(A) \pi(z) \mu(dz) = \int_K \pi(z) \mu(dz) \mbox{ for all } A \in \Sigma
\end{equation}
The end-to-end kernel is defined fir all $x \in X_P$ such that $p(x) > 0$ as:
\begin{equation}
k_x(A) := \int_U k'_{x,u}(A \times U) q_x(u) \mu_U(du) \;\; \mbox{for all} \;\; A \in \Sigma_P, x \in X
\end{equation}
Stationarity of the end-to-end kernel with respect to the measure induced by $p$ is:
\begin{equation}
\int_X k_x(A) p(x) \mu_P(dx) = \int_K p(x) \mu_P(dx) \mbox{ for all } A \in \Sigma_P
\end{equation}
Expanding:
\begin{align*}
    \int_X k_x(A) p(x) \mu_P(dx) &= \int_X \left( \int_U k'_{x,u}(A \times U) q_x(u) \mu_Q(du) \right) p(x) \mu_P(dx)\\
    &= \int_{X \times U} k'_{x,u}(A \times U) q_x(u) p(x) (\mu_P \times \mu_Q)(dz) \;\; [\mbox{ Tonelli's theorem }]\\ % TODO check
    &= \int_{Z} k'_{x,u}(\{(x', u') \in Z : x' \in A\}) \pi(z) \mu(dz)\\ % TODO justify
    &= \int_{\{(x, u) \in Z : x \in A\}} \pi(z) \mu(dz)\;\;\; [\mbox{ Stationarity of $k'$ with respect to $\pi$}]\\
    &= \int_{\{(x, u) \in Z : x \in A\}} q_x(u) p(x) \mu(dz)\\
    &= \int_K \left( \int_U q_x(u) \mu_Q(du) \right) p(x) \mu_P(dx)\\
    &= \int_K p(x) \mu_P(dx)
\end{align*}
% TODO characterize the various assumptions that allow us to e.g. rearrange the order of integration, etc.

%\paragraph{Proof of stationarity}
%We need the composition of the two programs to define a valid probabilistic program with density $\pi$ that is absolutely continuous with respect to the refernce measure $\mu$.
%We also need there to be a particular relationship between $\pi$ and $p$.
%The involution part of the kernel is a kernel on the combined space $(Z, \Sigma_Z, \mu)$.
%\[
%k'_z(B_Z) = [f(z) \in B_Z] \alpha(z) + [z \in B_Z] (1 - \alpha(z))
%\]
%The kernel of Algorithm 1 is defined by:
%\[
%k_t(B_T) := \int_{U_t} q_{t}(u) k'_{(t, u)}(\{(t', u') \in Z : t' \in B_T\}) \mu_{Q,t}(du)
%\]
%We want to show it is stationary:
%\begin{align}
%\int_T k_t(B_T) p(t) \mu_P(dt) &= p(B_T) \mbox{ for all } B_T \in \Sigma_P\\
%\int_T \left( \int_{U_t} q_{t}(u) k'_{(t, u)}(\{(t', u') \in Z : t' \in B_T\}) \mu_{Q,t}(du) \right) p(t) \mu_P(dt) &= p(B_T)\\
%\sum_{i} \int_{T_C} \left( \int_{U_t} q_{t}(u) k'_{(t, u)}(\{(t', u') \in Z : t' \in B_T\}) \mu_{Q,t}(du) \right) p(i, t_c) \mu_{P_C,i}(dt_c) &= p(B_T)\\ % separate out discrete part of t (i) and continuous part of t (t_c)
%\sum_{i} \int_{T_C} \left( \int_{U_i} q_{t}(u) k'_{(t, u)}(\{(t', u') \in Z : t' \in B_T\}) \mu_{Q,i}(du) \right) p(i, t_c) \mu_{P_C,i}(dt_c) &= p(B_T)\\ % use that the reference measure mu_{Q,t} only depends on the discrete part
%..\\
%\int_{Z} \pi(t, u) k'_{t,u}(\{(t', u') \in Z : t' \in B_T\}) \mu(dz) &= p(B_T)\\
%\pi(\{(t', u') \in Z : t' \in B_T\}) &= p(B_T)\\
%\end{align}
%
%the set of addresses $\mathcal{K}$ is partitioned into two spaces $\mathcal{K}_1$ and $\mathcal{K}_2$\\
%
%each structure $S$ partitions into two structures $S_1$ and $S_2$
%
%then $Z := \cup_{S \in \mathcal{S}} \{(S, \mathbf{x}) : \mathbf{x} \in \times_{k \in S} X_k \}$\\
%
%Space for $Z$:
%\[
%\cup_{S \in \mathcal{S}} \{((\mathcal{K}_1 \cap S) \cup (\mathcal{K}_2 \cap S), \mathbf{x_1}, \mathbf{x_2}) : \mathbf{x_1} \in \times_{k \in S_1} X_k, \mathbf{x_2} \in \times_{k \in S_2} X_k\}
%\]
%
%Space for $T$:
%\[
%\cup_{S_1 \in \mathcal{S}} \{(S_1, \mathbf{x_1}) : \mathbf{x_1} \in \times_{k \in S_1}\}
%\]
%
%\begin{align}
%\pi(
%\cup_{S \in \mathcal{S} : K_1 \cap S = S_1} \{(S_1 \cup (\mathcal{K}_2 \cap S), \mathbf{x_1}, \mathbf{x_2}) : \mathbf{x_1} \in B_{S_1}, \mathbf{x_2} \in \times_{k \in S_2} X_k\}
%) &= p(B_T)\\
%\sum_{S \in \mathcal{S} : K_1 \cap S = S_1} \int_{B_{S_1} \times \otimes_{k \in S_2} X_k} \pi(S_1, S_2, \mathbf{x}_1, \mathbf{x}_2) \mu_{S_1 \cup S_2}(d \mathbf{x}_1 \mathbf{x}_2) &= p(B_T)\\
%\sum_{S \in \mathcal{S} : K_1 \cap S = S_1} \int_{B_{S_1} \times \otimes_{k \in S_2} X_k} p(S_1, \mathbf{x}_1) q_{(S_1,\mathbf{x}_1)}(S_2, \mathbf{x}_2) \mu_{S_1 \cup S_2}(d \mathbf{x}_1 \mathbf{x}_2) &= p(B_T)\\
%\sum_{S \in \mathcal{S} : K_1 \cap S = S_1} \int_{B_{S_1}} p(S_1, \mathbf{x}_1) \left( \int_{\otimes_{k \in S_2 X_k}} q_{(S_1,\mathbf{x}_1)}(S_2, \mathbf{x}_2) \mu_{S_2}(d \mathbf{x}_2) \right) \mu_{S_1}(d \mathbf{x}_1) &= p(B_T) [\mbox{Fubini / Tonnelli?}]\\
%\sum_{S_2 \subseteq K_2 : S_1 \cup S_2 \in \mathcal{S}} \int_{B_{S_1}} p(S_1, \mathbf{x}_1) \left( \int_{\otimes_{k \in S_2 X_k}} q_{(S_1,\mathbf{x}_1)}(S_2, \mathbf{x}_2) \mu_{S_2}(d \mathbf{x}_2) \right) \mu_{S_1}(d \mathbf{x}_1) &= p(B_T)\\
%\int_{B_{S_1}} p(S_1, \mathbf{x}_1) \left( \sum_{S_2 \subseteq K_2 : S_1 \cup S_2 \in \mathcal{S}} \int_{\otimes_{k \in S_2 X_k}} q_{(S_1,\mathbf{x}_1)}(S_2, \mathbf{x}_2) \mu_{S_2}(d \mathbf{x}_2) \right) \mu_{S_1}(d \mathbf{x}_1) &= p(B_T) [\mbox{Fubini / Tonnelli?}]\\
%\end{align}
%It suffices to show that
%\begin{align}
%\sum_{S_2 \subseteq K_2 : S_1 \cup S_2 \in \mathcal{S}} \int_{\otimes_{k \in S_2 X_k}} q_{(S_1,\mathbf{x}_1)}(S_2, \mathbf{x}_2) \mu_{S_2}(d \mathbf{x}_2) = 1 \mbox{ for all } (S_1, \mathbf{x}_1) \in T
%\end{align}
%It suffices to show that for each $(S_1, \mathbf{x}_1) \in T$, we have that $q_{(S_1, \mathbf{x}_1)}$ is the density of a (terminating with probability one) probabilistic program with structruers $\mathcal{S}_2$ such that
%\[
%\mathcal{S}_2 = \{S_2 \subseteq K_2 : S_1 \cup S_2 \in \mathcal{S}\}
%\]
%
%\[
%B_1 = \cup_{S_1 \in \mathcal{S}_1} \{(S_1, \mathbf{x}_1) : \mathbf{x}_1 \in B_{S_1}\}\;\;\; \mbox{where} \;\; B_{S_1} \in \otimes_{k \in S_1} \Sigma_{k} \;\;\; [\mbox{Measurable set } B_1]
%\]
%% TODO the proof above should have a sum over S_1



% NOTE for each $t$ there is a different reference measure...
% we need to restrict q so that for each discrete part of $t$, the reference measure is the same
% (which implies that the same sets of random choices are made?)
% that will allow us to 

\subsection{A requirement on Densities for Involutive MCMC with Probabilistic Programs} \label{sec:technical-requirement}
TODO: consider cutting this or moving to appendix -- it is a complicated technical requirement on programs

% TODO cut this??
To define the model and auxiliary densities used in involutive MCMC in Section~\ref{sec:involutive-mcmc} using probabilistic programs, we write one probabilistic program ($P$) to define the model's probability distribution, and another probabilistic program ($Q$) to define the set of auxiliary distributions.
The model reference measure $(X, \Sigma_P, \mu_P)$ and density that were required in Section~\ref{sec:involutive-mcmc} are set to the probabilistic program's reference measure and density $p$ on traces as defined above (so that $X := T$).
To define the auxiliary densities, we use a second probabilistic program $Q$ that is parametrized by (i.e. takes as input) traces of the model program $P$.
The set of possible inputs to $Q$ is $\{x \in T : p(x) > 0\}$, and for each such $x$ the probabilistic program $Q$ defines a density $q_x : T \to [0, \infty)$ with respect to the reference measure on traces.\footnote{
Note that we the same measure space $(T, \Sigma, \mu)$ on traces for both the model and auxiliary probabilistic program.
If both programs sample some random choice at the same address $k$ and require different measure spaces $(V_k, \Sigma_k, \mu_k)$ for the address, this can be handled formally by making the addresses sampled by the two programs disjoint by prepending either the prefix `p.' or `q.' to addresses.
This is only required for book-keeping in the formalism, and these prefixes do not need to be actually added to the addresses used in the programs.}

The involutive MCMC framework of Section~\ref{sec:involutive-mcmc} requires that $Z := \{(x, y) \in X \times Y : \pi(x, y) > 0\}$ is $\mu_P \times \mu_Q$-measurable.
We now give a sufficient condition for this to hold.
Let $D \subseteq \mathcal{K}$ denote the subset of addresses that are discrete (i.e. where $V_k$ is a countable set and $\mu_k$ is the counting measure).
For $\mathbf{x} \in \times_{k \in A} V_k$ let $\mathbf{x} = (\mathbf{d}, \mathbf{c})$ where $\mathbf{d} \in \times_{k \in A \cap D} V_k$ and $\mathbf{c} = \times_{k \in A \setminus D} V_k$, so that $\mathbf{d}$ is the discrete part of $\mathbf{x}$ and $\mathbf{c}$ is the non-discrete part.
 %TODO make this a proposition
\begin{lemma}
Suppose that $p$ and $q$ are such that $p(K, (\mathbf{d}, \mathbf{c})) > 0$ implies
$p(K, (\mathbf{d}, \mathbf{c}')) > 0$ for all $\mathbf{c}' \in \prod_{k \in A \setminus D} V_k$,
and that $q_x(K, (\mathbf{d}, \mathbf{c})) > 0$ where $x = (\tilde{A}, \tilde{\mathbf{d}}, \tilde{\mathbf{c}})$ implies that
$q_{x'}(K, (\mathbf{d}, \mathbf{c}')) > 0$ for all $\mathbf{c}' \in \prod_{k \in A \setminus D} V_k$ and all $x' = (\tilde{A}, \tilde{\mathbf{d}}, \tilde{\mathbf{c}}')$ where $\tilde{\mathbf{c}}' \in \prod_{k \in \tilde{A} \setminus D} V_k$.
Then, $Z := \{(x, y) \in X \times Y : \pi(x, y) > 0\}$ is $\mu \times \mu$-measurable where $\mu$ is the reference measure on traces.
\end{lemma}
\begin{proof}
For $p$ and $q$ satisfying these conditions,
$Z = \cup_{(K_1,K_2,\mathbf{d}_1,\mathbf{d}_2) \in E} \{((K_1, (\mathbf{d}_1, \mathbf{c}_1)), (K_2, (\mathbf{d}_2, \mathbf{c}_2))) : \mathbf{c}_1 \in \times_{k \in K_1 \setminus D} V_k, \mathbf{c}_2 \in \times_{k \in K_2 \setminus D} V_k\}$ for some countable set $E \subseteq \{(K_1, K_2, \mathbf{d}_1, \mathbf{d}_2) : K_1, K_2 \subseteq \mathcal{K}, |K_1| < \infty, |K_2| < \infty, \mathbf{d}_1 \in \times_{k \in K_1 \cap D} V_k, \mathbf{d}_2 \in \times_{k \in K_2 \cap D} V_k\}$ of address sets and discrete choice values for both programs.
The measure of $Z$ is
$(\mu \times \mu)(Z) = \sum_{(K_1,K_2,\mathbf{d}_1,\mathbf{d}_2) \in E} \prod_{k \in (K_1 \setminus D) \cup (K_2 \setminus D)} \mu_k(V_k)$.
% TODO double check me.,
\end{proof}

Intuitively, this requirement means that for both the model probabilistic program $P$ and the auxiliary probabilistic program $Q$, the support of a random choice that is not discrete cannot depend on the value of another non-discrete random choice.
Additionally, the support of non-discrete random choices in $Q$ cannot depend on the value of non-discrete random choices in the input $x$, which is a trace of $P$.
This requirement defines a notion \emph{well-behavedness} for a probabilistic program ($P$) and an additional notion of well-behavedness for a pair of probabilistic programs that are sequenced one after the other ($P$ and $Q$).
% TODO: prove that if Q satisfeies the criterion, then the composition P circ Q satisfies the single-program criterion..


\end{document}
